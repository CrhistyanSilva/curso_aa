{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Redes Neuronales\n",
    "### Aprendizaje Automático - Instituto de Computación - UdelaR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Supongamos que tenemos una tarea de aprendizaje supervisada donde, a partir de un vector $x^T = (x_1, x_2, \\ldots, x_n)$ con $n$ atributos se busca construir una función (hipótesis) $h_{\\theta}(x): \\mathbb{R}^{n} \\to \\mathbb{R}$ que prediga la salida $y \\in \\mathbb{R}$, a partir de un conjunto de entrenamiento. El problema de aprendizaje para las redes neuronales consiste en aprender los parámetros $\\theta$ a partir de un conjunto de entrenamiento $\\{(x^{(i)},y^{(i)})\\}$ que tiene $m$ elementos y donde cada $(x^{(i)},y^{(i)})$ es una _instancia_ de entrenamiento.  \n",
    "\n",
    "Si la función de hipótesis $h_{\\theta}(x)$ no es lineal, sabemos que podemos utilizar atributos no lineales, resultado de la combinación de atributos de entrada, y aplicar regresión logística, por ejemplo. El problema con esta aproximación es que el número de parámetros crecerá exponencialmente con la cantidad de atributos, lo que vuelve computacionalmente imposible el problema cuando el número de atributos es muy grande. Las redes neuronales permiten aprender hipótesis complejas de forma eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unidad sigmoide\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/logistic%20unit.PNG\"  alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Dado un vector de entrada  $x^T = (x_1, x_2, \\ldots, x_n)$, la red neuronal más simple que puede construirse es equivalente a la regresión logística, y está compuesta por una primera capa de neuronas con los atributos de entrada (a lo que llamaremos _capa de entrada_, y denotaremos también como $a^{(1)})$, y una segunda capa compuesta por una sola neurona (o _unidad sigmoide_), que calcula la combinación lineal de las entradas y le aplica la función sigmoide (llamada _función de activación_), para obtener una salida real. A partir de esta salida, podremos tomar una decisión (por ejemplo, para clasificar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unidad sigmoide\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/logistic%20unit.PNG\"  alt=\"Drawing\" style=\"width: 450px;\"/> \n",
    "$$ x \\in  \\mathbb{R}^{n} = a^{(1)} = \\left[ \\begin{array}{c} x_1\\\\\\vdots\\\\x_n \\end{array}\\right]$$\n",
    "\n",
    "Para esta red de una sola neurona, nuestra función de hipótesis será:\n",
    "\n",
    "$$ h_\\theta(x) =  a^{(2)} \\in \\mathbb{R} = g(w^{(1)}\\cdot x + b^{(1)} ) $$\n",
    "\n",
    "siendo $ w^{(1)} = (w_1^{(1)} \\ldots w_n^{(1)}) $ el conjunto de parámetros para la combinación lineal calculados por la neurona de la capa 2 (también llamados _pesos_), $b^{(1)}$ un término independiente de sesgo, y $g(z)$ la _función de activación_ (en nuestro ejemplo, la función logística). Obsérvese que hemos extendido la definición de $g$ para que reciba un vector y calcule el resultado para cada uno de sus elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Algunas observaciones:\n",
    "\n",
    "* Tanto en las neuronas como en los parámetros, el superíndice indica la capa a la que pertenece. Los parámetros con superíndice $i$ multiplican a los valores obtenidos en la capa $i$ y el resultado sirve de entrada a la capa $i+1$\n",
    "* El valor de salida de cada neurona $a^{(j)}_i$ se conoce como _activación_. El valor intermedio $z^{(j)}=b^{(j)} + w^{(j)}\\cdot x$ es conocido también como entrada ponderada de la neurona (y veremos más adelante la utilidad de identificarla por separado)\n",
    "* En este curso seguiremos la terminología usual en redes neuronales, llamando $w$ a los parámetros (en lugar de $\\theta$, como hicimos en el módulo de regresión logística). Pero son exactamente los mismos, al igual que el término de sesgo.\n",
    "* Una forma alternativa de presentar la combinación lineal, es definir un parámetro adicional $w_0$ y agregar a $x$ (y a todas las entradas de las neuronas), un valor dummy $1$ al principio, permitiendo incluir el sesgo dentro del producto de los vectores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Las redes neuronales son una generalización del ejemplo anterior: en cada una de las capas puede haber más de una neurona (que recibe como entrada los resultados de la capa anterior), y pueden introducirse capas intermedias (también llamadas _capas ocultas_).\n",
    "\n",
    "Por lo tanto, generalizando el caso anterior tendremos: \n",
    "\n",
    "$$ a^{(1)} \\in  \\mathbb{R}^{n} =  x = \\left[ \\begin{array}{l} x_1\\\\\\vdots\\\\x_n \\end{array}\\right] $$\n",
    "\n",
    "\n",
    "$$ a^{(j)} \\in  \\mathbb{R}^{S_j} =  \\left[ \\begin{array}{l} a^{(j)}_1\\\\\\vdots\\\\a^{(j)}_{s_j} \\end{array}\\right] = g(W^{(j-1)} \\cdot a^{(j-1)} + b^{(j-1)})$$\n",
    "\n",
    "siendo $s_j$ el número de neuronas en la capa $j$, y $W^{(j)}$ la matriz de pesos que define el mapeo desde la capa $j$ a la capa $j+1$. \n",
    "\n",
    "Este modelo de redes neuronales donde cada capa está conectada con la siguiente (y donde, por lo tanto, no existen loops) es conocido como _redes feedforward_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "La matriz $W^{(j)}$ tiene en sus filas los pesos asociados a la combinación lineal de las entradas de la unidad $i$ de la capa $j+1$, que son resultados de la activación de las unidades en la capa $j$:\n",
    "\n",
    "$$ W^{(j)}= \\left ( \\begin{array} {cccc} \n",
    "w^{(j)}_{11} & w^{(j)}_{12} & \\cdots & w^{(j)}_{1s_{j}}\\\\\n",
    "w^{(j)}_{21} & w^{(j)}_{22} & \\cdots & w^{(j)}_{2s_{j}}\\\\\n",
    "\\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "w^{(j)}_{s_{j+1}1} & w^{(j)}_{s_{j+1}2} & \\cdots & w^{(j)}_{s_{j+1}s_{j}}\\\\\n",
    "\\end{array}\\right )$$\n",
    "\n",
    "Podemos observar que $W^{(j)} \\in  \\mathbb{R}^{s_{j+1}} \\times \\mathbb{R}^{s_{j}}$: tiene tantas filas como neuronas hay en la capa $j+1$, y tantas columnas como neuronas hay en la capa $j$. Cada valor $w^{(j)}_{ik}$ de la matriz debe leerse como el peso asociado a la i-ésima neurona de la capa $j+1$, correspondiente a la entrada proveniente de la k-ésima neurona de la capa $j$.\n",
    "\n",
    "De forma similar, el vector de sesgo incluye un componente por cada neurona de la capa anterior:\n",
    "\n",
    "$$ b^{(j)}=  (b^{(j)}_{1}, b^{(j)}_{2}, \\cdots b^{(j)}_{s_{j}})^T $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Supongamos que tenemos una red con dos entradas, y tres unidades en la primera capa oculta. Nuestra matriz de pesos $W^{(1)}$ lucirá así (eliminamos el supraíndice en los componentes para que se vea mejor):\n",
    "\n",
    "$$ W^{(1)} \\in \\mathbb{R^{3 \\times 2}}= \\left ( \\begin{array} {cc} \n",
    "w_{11} & w_{12}\\\\\n",
    "w_{21} & w_{22}\\\\\n",
    "w_{31} & w_{32}\n",
    "\\end{array}\\right )  \\;\\;\n",
    ", \\;\\; b^{(1)} \\in \\mathbb{R^{2 \\times 1}} =  \\left ( \\begin{array} {c} \n",
    "b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "\\end{array}\\right )  $$\n",
    "\n",
    "Si queremos obtener *todos* los valores de $z^{(2)}$:\n",
    "\n",
    "$$ z^{(2)} \\in \\mathbb{R^{3 \\times 1}} = W^{(1)} \\cdot a^{(1)} + b^{(1)} $$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forward propagation (Propagación hacia adelante)\n",
    "\n",
    "El proceso de calcular los valores de salida de cada capa, y utilizarlo como entrada para la siguiente, hasta obtener el valor final de $h_\\theta(x)$ es conocido como _forward propagation_. Veremos algunos ejemplos \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Supongamos que tenemos una red neuronal con dos valores de entrada (que supondremos binarios) y queremos construir una red que calcule el OR lógico de ambos valores. Para ello, definiremos una arquitectura con dos entradas, y una sola neurona, que nos dará la salida necesaria. Comprobaremos que utilizando $W^{(1)} \\in \\mathbb{R}^{2 \\times 1} = ( 20\\  20)$ y $b^{(1)} \\in \\mathbb{R}^{1 \\times 1}=(-10)$ estaremos computando la función que queremos. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Primero calculamos el resultado de la red para la entrada $x=(0,0)^T$: \n",
    "\n",
    "$$ x \\in  \\mathbb{R}^{2 \\times 1} = a^{(1)} = \\left[ \\begin{array}{c} 0\\\\0\\\\ \\end{array}\\right]$$\n",
    "\n",
    "$$ a^{(2)} \\in  \\mathbb{R}^{1 \\times 1} = g(W^{(1)}\\cdot x + b^{(1)}) = g (20 \\times 0+20 \\times 0-10) = g(-10) \\approx 0$$\n",
    "\n",
    "Es decir que cuando $x_1=0$ y $x_2=0$, entonces $h(x) \\approx 0$, lo cual corresponde a la definición de OR lógico. Análogamente, se puede ver que en las otras combinaciones de la entrada, se obtienen los valores adecuados para la función. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Para ver un caso más interesante, construiremos una red neuronal para calcular la función XNOR, que devuelve $1$ si ambas entradas valen $1$, o ambas entradas valen $0$. Esta función puede escribirse como OR(AND$(x_1,x_2)$,NOR$(x_1,x_2)$) (comprobarlo), y a partir de esto construiremos una red neuronal de tres capas: las dos neuronas de la primera capa corresponden a las entradas $x_1, x_2$, la segunda capa (oculta), tiene dos neuronas: una computa la función AND y la otra la función NOR. Finalmente, la tercera capa (de salida) tiene una sola neurona que computa el OR de los resultados de las neuronas de la capa 2, para obtener el resultado. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- La entrada será igual que en el caso anterior: $ x \\in  \\mathbb{R}^{2 \\times 1} = a^{(1)} $\n",
    "\n",
    "- En la capa 2, tendremos los parámetros correspondientes a la función AND en la primera fila (verifíquelo en cada caso), y a los de NOR en la segunda, lo que nos da la siguiente matriz de parámetros y sesgo\n",
    "\n",
    "$$W^{(1)} \\in  \\mathbb{R}^{2 \\times 2}  = \\left [ \\begin{array}{rr} 20&20\\\\ -20&-20\\\\ \\end{array}\\right], b^{(1)}  \\in \\mathbb{R}^{2 \\times 1}=\\left [ \\begin{array}{r} -30\\\\10\\\\\\end{array}\\right]$$\n",
    "\n",
    "\n",
    "- En la capa 3, hay una sola neurona que calcula el OR de sus entradas:\n",
    "\n",
    "$$W^{(2)}  \\in  \\mathbb{R}^{1 \\times 2} = \\left [ \\begin{array}{rr} 20&20 \\end{array}\\right], b^{(2)}  \\in  \\mathbb{R}^{1 \\times 1}=\\left [ \\begin{array}{r} -10\\\\\\end{array}\\right]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Podemos comprobar mediante forward propagation que nuestra red se comporta como esperamos. Supongamos que las dos entradas son 0: \n",
    "\n",
    "$$ x \\in  \\mathbb{R}^{2 \\times 1} = a^{(1)} = (0,0)^T$$\n",
    "- Obtenemos los valores de activación de la segunda capa: \n",
    "\n",
    "$$ a^{(2)} \\in  \\mathbb{R}^{2 \\times 1} = g(W^{(1)}\\cdot a^{(1)} + b^{(1)})  = g ((-30\\  20)^T) \\approx (0\\  1)^T$$\n",
    "\n",
    "- El primer valor de $ a^{(2)}$ es $0$, equivalente al AND de las entradas, y el segundo es 1, el NOR de las entradas. \n",
    "\n",
    "- Con estos valores de salida como entrada para la ùnica neurona de salida, calculamos la activación: \n",
    "\n",
    "$$ a^{(3)} \\in  \\mathbb{R^{1 \\times 1}} =  g(W^{(2)}\\cdot a^{(2)} + b^{(2)})  = g ((10)) \\approx (1)$$\n",
    "\n",
    "- Por lo tanto, nuestra funciòn devuelve $1$ cuando las dos entradas son 0.\n",
    "\n",
    "**Ejercicio: repita el proceso, complete la tabla de valores, y verifique que la red computa la función XNOR. Verifique que las matrices tienen las dimensiones correctas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje en Redes Neuronales\n",
    "\n",
    "Al igual que en los métodos anteriores, es importante entender cómo funciona el aprendizaje en redes neuronales. En este caso, lo que intentaremos aprender a partir de los datos de entrenamiento será las matrices de pesos $W^{(j)}$ y $b^{(j)}$ de las diferentes capas. \n",
    "\n",
    "Fijemos algunas definiciones:\n",
    "\n",
    "* $L$ es el número de capas de la red neuronal\n",
    "* $s_l$ es el número de neuronas de la capa $l$\n",
    "* $K$ es el número de neuronas en la capa de salida (por lo tanto, $h_\\Theta(x) \\in \\mathbb{R}^K$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje en Redes Neuronales\n",
    "\n",
    "\n",
    "Una función de costo para redes neuronales que podemos utilizar es una generalización de la función de mínimos cuadrados, que utilizamos para la regresión lineal, pero sumando en todas las unidades de la capa de salida:\n",
    "\n",
    "$$J(W,b) = - \\frac{1}{2m} \\sum_{i=1}^m \\sum_{k=1}^{k=K} (y^{(i)} - a^{(L)}_k)^2 $$\n",
    "\n",
    "\n",
    "Estas función no es la única posible. De hecho, basta con suponer que la función de costo puede escribirse como un promedio de los costos de los ejemplos de entrenamiento, y que puede ser escrita como función de las salidas de la red. A partir de la primera propiedad, eliminaremos los supraíndices en los cálculos y supondremos que estamos calculando el costo para un ejemplo dado. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura recomendada:  [A list of cost functions used in neural networks, alongside applications](https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje en Redes Neuronales\n",
    "\n",
    "Para aprender los pesos de las redes neuronales, aplicaremos exactamente el mismo procedimiento que utilizamos para la regresión: intentaremos minimizar la función de costo, utilizando descenso por gradiente. Para ello, necesitaremos calcular las derivadas parciales \n",
    "de $J$ respecto a cada uno de los pesos de la red. Esto es sencillo en el caso de las neuronas de salida, pero un poco más complejo en el caso de las unidades ocultas (porque no podemos calcular directamente el error cometido por la neurona).  El algoritmo de backpropagation, precisamente, permite calcular de forma eficiente estas derivadas.\n",
    "\n",
    "Recordemos que la regla de actualización (o _regla delta_) en el descenso por gradiente es la siguiente:\n",
    "\n",
    "$$ \\Delta w_{ji} = - \\alpha \\frac{\\partial J}{\\partial w_{ji}} $$\n",
    "\n",
    "donde los $w_{ji}$ son los parámetros asociados a la función $J$ que queremos minimizar. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation\n",
    "\n",
    "Aplicando la regla de la cadena, podemos ver a la derivada de $J$ en dos partes: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w^{(l)}_{ji}} =  \\frac{\\partial J}{\\partial z^{(l+1)}_{j}} \\frac{\\partial z^{(l+1)}_j}{ w^{(l)}_{ji}}$$\n",
    "\n",
    "\n",
    "El segundo componente ya lo calculamos en la regresión lineal, y vale $x_{ji}$, es decir el valor de entrada a la neurona $j$, salida de la neurona $i$ de la capa anterior. Al primer componente (que generaliza la idea del \"error\" cometido por la neurona respecto al valor de la instancia de entrenamiento correspondiente), lo llamaremos $\\delta^{(l)}_j$. \n",
    "\n",
    "$$\\delta^{(l)}_j = \\frac{\\partial J  } {\\partial z^{(l)}_j}  $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Intuitivamente, si incrementamos en $\\Delta z^{(l)}_j$ el valor de la combinación lineal de la entrada, la salida de la neurona será  $g(z^{(l)}_j+\\Delta z^{(l)}_j)$. Este valor se propagará por la red, para llegar a un cambio final de $\\frac{\\partial J}{\\partial z^{(l)}_j}  \\Delta z^{(l)}_j$. En caso de que esta derivada final tenga un valor grande, y modifiquemos el valor $\\Delta z^{(l)}_j$ con signo opuesto, podremos reducir el valor de la función de costo (utilizando descenso por gradiente). Si es el valor de la derivada es cercano a 0, entonces ese parámetro no modifica mucho el costo, por lo que no aporta al costo final (y por lo tanto, es razonable no modificarlo demasiado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation - Neuronas de salida\n",
    "\n",
    "Esta error  puede calcularse directamente para las neuronas de salida, luego de haber calculado los valores de activación $a^{(L)}$, utilizando nuevamente la regla de la cadena:\n",
    "\n",
    "$$\\delta^{(L)}_j = \\frac{\\partial J} {\\partial a^{(L)}_j} g'(z^{L}_j) $$ \n",
    "\n",
    "En el caso en que J sea la función de mínimos cuadrados y la función de activación es la sigmoide, esto es equivalente a:\n",
    "\n",
    "\n",
    "$$\\delta^{(L)}_j = {(a^{(L)}_j - y_j}) \\sigma(z^{L}_j)(1-\\sigma(z^{L}_j) $$ \n",
    "\n",
    "O, en formato vectorial: \n",
    "\n",
    "$$ \\delta^{(L)} = (a^{(L)}-y) \\odot g'(z^{(L)})$$\n",
    "\n",
    "siendo $y$ el valor objetivo de la instancia de entrenamiento, y donde $\\odot$ representa al producto de Hadamard (es decir el producto componente a componente de los vectores involucrados). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* El primer factor está relacionado a la derivada de la función de costo respecto a cada uno de los valores de activación de la capa de salida (y por lo tanto mide qué tanto cambia el costo como función del valor de activación), y el segundo a la derivada de la función de activación (es decir, cómo está cambiando la función de activación respecto a su entrada). En el caso de la función sigmoide, su derivada puede calcularse de forma muy sencilla: $g'(z)=g(z)(1-g(z))$.\n",
    "\n",
    "* Para derivar esta igualdad, considere \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial z_j} = \\frac{\\partial{J}}{\\partial{a_j}} \\frac{\\partial{a_j}}{\\partial{z_j}} $$\n",
    "\n",
    "(Puede encontrar la derivación en el capítulo 4 de libro de Mitchell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation - Unidades ocultas\n",
    "\n",
    "En el caso de las unidades ocultas, no contamos con el valor \"correcto\", y por lo tanto no podemos calcular directamente el error, sino que debemos hacerlo a partir de los errores de la capa siguiente. Es decir, \"propagaremos hacia atrás\" el error, intentando calcular cómo afecta el valor de salida de cada neurona a las entradas de la capa siguiente. \n",
    "\n",
    "Esto nos lleva a que, si $output(j)$ son los valores de salida de una neurona, entonces:\n",
    "\n",
    "$$\\delta^{(l)}_j = \\sum_{k \\in output(j)} \\delta^{(l+1)}_{k} w^{(l)}_{kj} g'(z^{(l)}_j) $$ \n",
    "\n",
    "\n",
    "Utilizando notación vectorial: \n",
    "$$ \\delta^{(l)} = (W^{(l)})^T \\delta^{(l+1)} \\odot g'(z^{(l)}) $$\n",
    "\n",
    "siendo $g'(z^{(l)})$ es la derivada de $g$ evaluada en cada uno de los elementos de $z^{(l)}$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Para derivar esta igualdad, considere \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial z^{(l)}_j} = \\sum_{k \\in output(j)}  \\frac{\\partial{J}}{\\partial{z_k}} \\frac{\\partial{z_k}}{\\partial{a_j}} \\frac{\\partial{a_j}}{\\partial{z_j}} $$\n",
    "\n",
    "(Puede encontrar la derivación en el capítulo 4 de libro de Mitchell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation - Pesos de sesgo\n",
    "\n",
    "En forma análoga a los casos anteriores, podemos ver que, en el caso de los pesos independientes, la derivada parcial es exactamente igual a $\\delta$:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b^{(l)}_j} = \\delta^{(l)}_j $$\n",
    "\n",
    "o, en su versión vectorial\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\delta $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Para derivar esta igualdad, considere \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial b^{(l)}_j} = \\sum_{k \\in output(j)}  \\frac{\\partial{J}}{\\partial{z_k}} \\frac{\\partial{z_k}}{\\partial{b_j}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation - Cálculo de derivadas para los pesos \n",
    "\n",
    "\n",
    "Recordemos que: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w^{(l)}_{ji}} =  \\frac{\\partial J}{\\partial z^{(l+1)}_{j}} \\frac{\\partial z^{(l+1)}_j}{ w^{(l)}_{ji}} $$\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial w^{(l)}_{ji}} = \\delta^{(l+1)}_j  \\frac{\\partial z^{(l)}_j}{ w^{(l)}_{ji}} =  \\delta^{(l+1)}_j a^{(l)}_i $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Obtenidos estos valores, ya podemos aplicar descenso por gradiente para buscar el mínimo de la función de costo. Para cada parámetro, tendremos: $w^{(l)}_{ji} \\leftarrow w^{(l)}_{ji} - \\alpha \\delta^{(l+1)}_j a^{(l)}_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### El algoritmo de backpropagation\n",
    "\n",
    "Resumiendo, el algoritmo de backpropagation permite obtener el mínimo de la función de costo en redes neuronales, calculando primero sus derivadas parciales respecto a cada parámetro de la red. Daremos aquí la versión que utiliza descenso por gradiente incremental. \n",
    "\n",
    "Entradas: \n",
    "- conjunto de entrenamiento $\\{(x^{(1)},y^{(1)}), \\ldots , (x^{(m)},y^{(m)}) \\}$, para cada ejemplo $(x,y)=(x^{(i)},y^{(i)})$\n",
    "- una red neuronal con $n$ entradas, con función de activación $g$.\n",
    "- una tasa de aprendizaje $\\alpha$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### El algoritmo de backpropagation\n",
    "\n",
    "Resumiendo, el algoritmo de backpropagation permite obtener el mínimo de la función de costo en redes neuronales, calculando primero sus derivadas parciales respecto a cada parámetro de la red. Daremos aquí la versión que utiliza descenso por gradiente incremental. \n",
    "\n",
    "\n",
    "1. Inicializar los pesos de la red con valores aleatorios pequeños (e.g. entre -.05 y .05)\n",
    "2. Mientras no se cumpla la condición de fin\n",
    "    \n",
    "    2.1. $a^{(1)}$ := $x$\n",
    "    \n",
    "    2.2 Para cada $l=2,3,\\ldots, L$ calcular $z^{(l)}=W^{(l-1)} a^{(l-1)} + b^{(l-1)}$ ; $a^{(l)} = g(z^{(l)})$\n",
    "\n",
    "    2.3. Calcular $\\delta^{(L)} = (a^{(L)}-y) \\odot g'(z^{(L)})$  (suponemos que la función de costo es mínimos cuadrados)\n",
    "\n",
    "    2.4. Propagar el error hacia atrás: para cada $l = L-1,L-2, \\ldots, 2$ calcular $\\delta^{(l)} = (W^{(l)})^T \\delta^{(l+1)} \\odot g'(z^{(l)})$\n",
    "\n",
    "    2.5 Actualizar los pesos de las capas $l=L,L-1,L-2,\\ldots ,2$:\n",
    "\n",
    "\n",
    "$$ W^{(l)} = W^{(l)} - \\alpha \\delta^{l+1} \\cdot (a^{l})^T$$\n",
    "\n",
    "$$ b^{(l)} = b^{(l)} - \\alpha \\delta^{l}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Video recomendado: [What is backpropagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U) 3Blue1Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje en Redes Neuronales\n",
    "\n",
    "* El orden para calcular los pesos es desde la última capa hacia atrás, hasta llegar a la segunda capa (la primera capa es la capa de entrada, y por lo tanto no tiene error). \n",
    "\n",
    "* La regla de actualización es similar a la regla delta utilizada para regresión lineal: depende de la entrada $x_{ij}$ y del valor del \"error\" de la neurona a la que llegamos. Este error, a su vez, depende de los errores de las capas siguientes, dependiendo de sus respectivos pesos y de cómo está creciendo la función de activación según la salida de la neurona. \n",
    "\n",
    "* Algunas posibles condiciones de finalización:\n",
    "    \n",
    "    - Número de iteraciones\n",
    "    - Accuracy en un conjunto de validación\n",
    "    - Error en en el conjunto de entrenamiento (Ojo con 😈)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje en Redes Neuronales\n",
    "\n",
    "* Si la activación de la neurona es cercana a 0 ( $a^{(l)}_j \\approx 0$),la modificación en el parámetro al aplicar descenso por gradiente será también pequeño. Decimos en este caso que el parámetro está _aprendiendo lentamente_.\n",
    "\n",
    "* Cuando una neurona de salida tiene un valor de activación cercano a 0, o cercano a 1, y dada la forma de la función sigmoide, tendremos $g'(z_j^{(L)})\\approx0$: el parámetro de esta neurona aprenderá lentamente, y diremos que la neurona está _saturada_. Lo mismo puede suceder en las capas anteriores.  Esto hace que en una neurona saturada, los pesos que llegan a esa neurona aprenderán lentamente. \n",
    "\n",
    "* Las ecuaciones que permiten calcular las derivadas parciales dependen de la función de activación solamente a través de su derivada. Por lo tanto, es posible elegir funciones de activación diferentes para lograr ciertos comportamientos de las redes neuronales.La literatura sobre distintas funciones de activación y de costo ha sido enorme en los últimos años.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funciones de activación \n",
    "\n",
    "- La función sigmoide no es la única (y ni siquiera la más utilizada) como función de activación de las neuronas. Recordemos algunas de sus propiedades:\n",
    "    - Toma valores entre 0 y 1, lo que permite analizar su salida como una probabilidad\n",
    "    - Es diferenciable\n",
    "    - Lleva los valores alejados de la media hacia 0 o 1\n",
    "    \n",
    "<img src=\"https://miro.medium.com/max/1400/1*6A3A_rt4YmumHusvTvVTxw.png\" alt=\"Sigmoide\" style=\"width: 450px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funciones de activación \n",
    "\n",
    "- La función [tangente hiperbólica](https://es.wikipedia.org/wiki/Tangente_hiperb%C3%B3lica) es parecida a la sigmoide, con algunas diferencias:\n",
    "    - Toma valores entre $-\\infty$ y $+\\infty$    \n",
    "    - Esto evita el problemas de saturación en el aprendizaje\n",
    "    - Lleva los valores alejados de la media hacia 0 o 1\n",
    "    - Derivada simple\n",
    "\n",
    "<img src=\"https://www.i2tutorials.com/wp-content/uploads/2019/09/Deep-learning-22-i2tutorials.png\" alt=\"Sigmoide\" style=\"width: 450px;\"/>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Funciones de activación \n",
    "\n",
    "- La función ReLU (Rectified Linear Unit) y sus variantes son las más populares, especialmente en redes muy grandes, porque permiten aprender más rápido \n",
    "\n",
    "    - Devuelve cero para entradas negativas o cero, y la misma entrada si es positiva, y, Por lo tanto, su rango es de 0 a infinito\n",
    "    - Su principal virtud es que no se satura, porque el gradiente es constante al crecer los valores de z\n",
    "    - Su derivada puede calcularse muy rápidamente\n",
    "    - Si los valores de activación son negativos, toma valor 0, lo que es bueno para el aprendizaje\n",
    "    \n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png\" alt=\"ReLU\" style=\"width: 400px;\"/>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Recomendado: [What are the advantages of ReLU over sigmoid function in deep neural networks?](https://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clasificación multiclase y activación Softmax\n",
    "\n",
    "¿Cómo podemos utilizar las redes neuronales para clasificar entre más de dos clases? \n",
    "\n",
    "La solución pasa por definir varias neuronas en la capa de salida (podemos observar que el modelo no lo impide), y que la función $h_\\theta(x)$ devuelva un vector, cuyos elementos sean los valores de activación de cada una de esas neuronas. \n",
    "Por ejemplo, si tenemos 4 clases posibles de salida, nuestros ejemplos de entrenamiento serán:\n",
    "\n",
    "$$ y^{(i)} \\in \\{ \\left[ \\begin{array}{c} 0\\\\0\\\\0\\\\1 \\end{array}\\right], \\left[ \\begin{array}{c} 0\\\\0\\\\1\\\\0 \\end{array}\\right], \\left[ \\begin{array}{c} 0\\\\1\\\\0\\\\0 \\end{array}\\right], \\left[ \\begin{array}{c} 1\\\\0\\\\0\\\\0 \\end{array}\\right] \\}$$\n",
    "\n",
    "Y la misma forma tendrá $h_\\theta(x)$. Al componente i-esimo de $h_\\theta(x)$ lo denotaremos $(h_\\theta(x))_i$. Si lo que interesa tener es una distribución de probabilidad entre los valores de las clases, podemos utilizar en la última capa una función de activación softmax (como vimos en regresión logística): una vez calculados los valores de $z$ de cada neurona de salida, devolvemos\n",
    "\n",
    "$$ \\text{softmax}(z) = \\left [ \\frac{e^{z_1}}{\\sum_{i=1}^k e^{z_i}}, \\frac{e^{z_2}}{\\sum_{i=1}^k e^{z_i}}, \\dots, \\frac{e^{z_k}}{\\sum_{i=1}^k e^{z_i}}  \\right ] $$\n",
    "\n",
    "- Se ha mostrado que la capa softmax también evita el problema del enlentencimiento en el aprendizaje (si se utiliza con una función de costo ligeramente diferente (conocida como log-likelihood)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ejemplo: si en la última capa oculta $j$ tenemos valores $(0.7, 0.6)$ para $a^{(j)}$, en la última capa tenemos una capa softmax con 4 neuronas, y tenemos una matriz $w^{(j)} \\in \\mathbb{R}^{2\\times4}$ de pesos, el cálculo queda así"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.28, 4.83, 0.97, 1.56])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.59690956, 0.38060634, 0.00801861, 0.01446549])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "w=np.array([0.6,8.1,0.3,7.7,0.1,1.5,1.2,1.2]).reshape(4,2)\n",
    "a=np.array([0.7,0.6])\n",
    "\n",
    "z=np.dot(w,a)\n",
    "\n",
    "display(z)\n",
    "np.exp(z)/np.sum(np.exp(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation en la práctica\n",
    "\n",
    "- A diferencia de los casos que vimos en las clases anteriores, la función de costo de una red neuronal no es convexa, por lo que siempre tenemos el riesgo de que Backpropagation nos lleve a un mínimo local. Sin embargo, en la práctica ha mostrado funcionar muy bien. Entender cuándo y por qué vamos a quedar en mínimos locales no es un problema con una solución general. Intuitivamente, dado que las redes neuronales tienen muchos parámetros, es más difícil que todas las direcciones lleguen a un mínimo al mismo tiempo. \n",
    "\n",
    "- Veamos algunas heurísticas  para evitar caer en mínimos locales.\n",
    "\n",
    "- **Inicialización de los parámetros**: para evitar que, al aprender, todos los parámetros ajusten al mismo valor, debemos inicializar los parámetros en valores diferentes a 0. Para eso, una solución es utilizar valores aleatorios entre $[-\\epsilon, \\epsilon]$ para inicializar cada uno de los parámetros. Estos valores deberían ser pequeños, para que las funciones hipótesis sean más suaves al comienzo, y disminuya el riesgo de quedar atrapados en un mínimo local. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backpropagation en la práctica\n",
    "\n",
    "- **Momentum**: una forma de mejorar la performance del algoritmo  es agregar un componente a la regla de actualización que haga que ésta dependa parcialmente de la actualización anterior. \n",
    "\n",
    " $$\\Delta w_{ji}(n) = \\alpha \\delta^{(l+1)}_j a^{(l)}_{i} + \\Delta w_{ji}(n-1)$$\n",
    " Esto busca favorece el movimiento en el descenso por gradiente en la misma dirección en la que se venía. Esto podría ayudar a superar mínimos locales, e incluso favorecer la velocidad de convergencia si el gradiente no está cambiando. \n",
    "\n",
    "- **Utilizar SGD**: el descenso por gradiente incremental, al considerar una instancia a la vez, tendrá diferentes mínimos en los gradientes calculados.\n",
    "\n",
    "- **Inicializar con diferentes pesos**: una forma de evitar los mínimos locales es intentar ajustar varias veces, utilizando diferentes valores de pesos iniciales, y elegir el mejor en un corpus de validación separado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient checking\n",
    "\n",
    "Cuando se está implementando backpropagation, es muy difícil detectar errores pequeños en el funcionamiento del algoritmo. Una forma mucho más sencilla (pero muchísimo más lenta) de aproximarse al cálculo del gradiente es la siguiente: dado un valor pequeño $\\epsilon$ (por ejemplo, $10^{-4}$), calcular:\n",
    "\n",
    "$$   \\frac{\\partial J(W)}{\\partial W} \\approx \\frac{J(W +\\epsilon ) - J(W-\\epsilon )}{2\\epsilon}$$\n",
    "\n",
    "\n",
    "Esta aproximación nos permite verificar que los valores que estamos calculando con backpropagation de las derivadas son correctos. Por supuesto, esto se utiliza durante el desarrollo del algoritmo: para el ajuste final de los parámetros se desactiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje de Representaciones\n",
    "\n",
    "La redes neuronales tienen la capacidad de aprender representaciones intermedias en las capas ocultas a partir de los datos. Estas representaciones (atributos), que no aparecieron en forma de atributos explícitos en la entrada, son sin embargo aprendidas y capturan propiedades de las instancias de entrada. Mostraremos un ejemplo muy sencillo, tomado del libro de Tom Mitchell. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/mitchell_rep_learning.png\" alt=\"Rep.Learning\" style=\"width: 500px;\" />\n",
    "\n",
    "- La red neuronal computa la función identidad, usando una capa oculta de tres unidades. En la figura puede verse que las capas ocultas están aprendiendo la representación binaria de la entrada (y esto \"comprime\" la representación de 8 bits a 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje de Representaciones\n",
    "\n",
    " $\\ $           |  $\\ $  \n",
    ":-------------------------:|:-------------------------:\n",
    "![](https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/mitchell_rep_learning2.png) | ![](https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/mitchell_rep_learning3.png)\n",
    "\n",
    "- Podemos ver cómo varían las activaciones en la capa oculta para la entrada \"01000000\"\n",
    "- Al comienzo, todas las activaciones están cercanas a 0.5, y luego se ajustan a los valores (0 1 0)\n",
    "- En la gráfica de la derecha vemos cómo se ajustan los pesos de cada una de las entradas en una de las unidades ocultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Referencias y material adicional\n",
    "\n",
    "- Machine Learning, Tom Mitchell. Capítulo 4.\n",
    "- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/), Michael Nielsen.\n",
    "- [Notas del curso CS229](http://cs229.stanford.edu/notes/cs229-notes1.pdf) de la Universidad de Stanford (disponible en la plataforma Coursera)\n",
    "- [Calculus on Computational Graphs: Backpropagation](http://colah.github.io/posts/2015-08-Backprop/) Chris Olah\n",
    "\n",
    "Para una excelente visión didáctica sobre redes neuronales y los algoritmos asociados, recomendamos los [videos](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) de 3Blue1Brown sobre el tema. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
