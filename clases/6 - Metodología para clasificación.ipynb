{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Metodología para clasificación\n",
    "### Aprendizaje Automático - Instituto de Computación - UdelaR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metodología para clasificación\n",
    "\n",
    "- Indepedientemente del método utilizado, existen etapas comunes para poder hacer aprendizaje supervisado (en particular, clasificación).\n",
    "\n",
    "- ¿Cuál es nuestra tarea?: dado un conjunto $X$ de instancias, cada una de ellas con una clase $y$ asociada, queremos construir una función de clasificación que, dada una instancia nueva, nos devuelva su clase.  \n",
    "\n",
    "- Algunas preguntas: ¿cómo aprendo la función?, ¿sobre qué instancias?, ¿cómo evalúo la performance de la función?\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/clasificador.PNG\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fase 1: Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preprocesamiento\n",
    "\n",
    "-  Vamos a suponer que, para poder entrenar un clasificador, debemos partir de un conjunto $D = \\{(x_i,y_i)\\}$, llamado conjunto de entrenamiento, donde cada instancia $x_i \\in \\mathbb{R}^n$ y $y_i \\in \\mathbb{R}$ (no todos los algoritmos de aprendizaje necesitan este formato de entrada, es solamente para fijar ideas)\n",
    "\n",
    "- (Des) afortunadamente, los conjuntos de datos que generalmente disponemos surgen de sensores, datos ingresados por humanos, fuentes diferentes, etc. Por lo tanto, debemos limpiarlos (_data cleaning_).\n",
    "\n",
    "- El formato de los datos originales puede ser diverso: elementos de un conjunto (categóricos), fechas, textos, imágenes, etc. Debemos buscar formas para convertirlos a un formato aceptable por el algoritmo (_data transformation_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preprocesamiento\n",
    "\n",
    "- Nuestros datos pueden venir de diferentes fuentes, debemos integrarlos (_data integration_)\n",
    "\n",
    "- Puede que, para ser más eficientes en los tiempos de aprendizaje, sea necesario agrupar datos, eliminar atributos o reducir el numero de instancias, buscando no perder infromación (_data reduction_)\n",
    "\n",
    "![Data Preprocessing](https://miro.medium.com/max/628/1*d1P90NT33rRKlJT7opFO8w.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Fuente de la imgen: [Data Preprocessing](https://medium.com/@silicon.smile1/data-preprocessing-b1552b4060f3) - Umar Farooq "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preprocesamiento - Valores faltantes\n",
    "\n",
    "\n",
    "- ¿qué hacemos si algún atributo de alguna instancia no tiene asignado un valor?\n",
    "\n",
    "- Opción 1: eliminar instancias. Problema: reduce el dataset.\n",
    "\n",
    "- Opción 2: asignar un valor especial (UNK, -1, 0, etc). Esto indica que, si faltan datos, quiere decir algo. \n",
    "\n",
    "- Opción 3: asignar el valor medio (o la mediana, o la moda) del atributo en el dataset.\n",
    "\n",
    "- Opción 4: asignar según el método de aprendizaje que estemos utilizando (e.g. lo visto en Árboles de Decisión)\n",
    "\n",
    "Observación: los valores que utilicemos debemos guardarlos para cuando evaluemos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Veamos un ejemplo utilizando pandas (ya que estamos, importamos otras bibliotecas que probablemente utilicemos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ejemplo: Titanic Dataset: listado de pasajeros del Titanica, indicando si sobrevivieron o no. Más detalles [aquí](https://www.kaggle.com/c/titanic). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Artun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1310</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1311</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zenn, Mr Philip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1312</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zievens, Rene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1313</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row.names pclass  survived  \\\n",
       "0             1    1st         1   \n",
       "1             2    1st         0   \n",
       "2             3    1st         0   \n",
       "3             4    1st         0   \n",
       "4             5    1st         1   \n",
       "...         ...    ...       ...   \n",
       "1308       1309    3rd         0   \n",
       "1309       1310    3rd         0   \n",
       "1310       1311    3rd         0   \n",
       "1311       1312    3rd         0   \n",
       "1312       1313    3rd         0   \n",
       "\n",
       "                                                 name      age     embarked  \\\n",
       "0                        Allen, Miss Elisabeth Walton  29.0000  Southampton   \n",
       "1                         Allison, Miss Helen Loraine   2.0000  Southampton   \n",
       "2                 Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   \n",
       "3     Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   \n",
       "4                       Allison, Master Hudson Trevor   0.9167  Southampton   \n",
       "...                                               ...      ...          ...   \n",
       "1308                               Zakarian, Mr Artun      NaN          NaN   \n",
       "1309                           Zakarian, Mr Maprieder      NaN          NaN   \n",
       "1310                                  Zenn, Mr Philip      NaN          NaN   \n",
       "1311                                    Zievens, Rene      NaN          NaN   \n",
       "1312                                   Zimmerman, Leo      NaN          NaN   \n",
       "\n",
       "                            home.dest room      ticket   boat     sex  \n",
       "0                        St Louis, MO  B-5  24160 L221      2  female  \n",
       "1     Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
       "2     Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male  \n",
       "3     Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
       "4     Montreal, PQ / Chesterville, ON  C22         NaN     11    male  \n",
       "...                               ...  ...         ...    ...     ...  \n",
       "1308                              NaN  NaN         NaN    NaN    male  \n",
       "1309                              NaN  NaN         NaN    NaN    male  \n",
       "1310                              NaN  NaN         NaN    NaN    male  \n",
       "1311                              NaN  NaN         NaN    NaN  female  \n",
       "1312                              NaN  NaN         NaN    NaN    male  \n",
       "\n",
       "[1313 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic=pd.read_csv('https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/data/titanic.csv')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Atributos faltantes\n",
    "\n",
    "Vamos a sustituir los atributos faltantes por el promedio de los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias sin valor: 680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.19418104265403"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Contamos cuántos NaN son\n",
    "print(\"Cantidad de instancias sin valor: {0}\".format(titanic['age'].isna().sum()))\n",
    "\n",
    "# Vemos el promedio de edad de los sobrevivientes, según la clase\n",
    "mean_age=titanic.mean()['age']\n",
    "display(mean_age)\n",
    "\n",
    "# Actualizamos con la mean_age de cada grupo\n",
    "titanic.loc[titanic['age'].isna(),'age']=mean_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.916700</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Artun</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1310</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1311</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zenn, Mr Philip</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1312</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zievens, Rene</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1313</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row.names pclass  survived  \\\n",
       "0             1    1st         1   \n",
       "1             2    1st         0   \n",
       "2             3    1st         0   \n",
       "3             4    1st         0   \n",
       "4             5    1st         1   \n",
       "...         ...    ...       ...   \n",
       "1308       1309    3rd         0   \n",
       "1309       1310    3rd         0   \n",
       "1310       1311    3rd         0   \n",
       "1311       1312    3rd         0   \n",
       "1312       1313    3rd         0   \n",
       "\n",
       "                                                 name        age     embarked  \\\n",
       "0                        Allen, Miss Elisabeth Walton  29.000000  Southampton   \n",
       "1                         Allison, Miss Helen Loraine   2.000000  Southampton   \n",
       "2                 Allison, Mr Hudson Joshua Creighton  30.000000  Southampton   \n",
       "3     Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.000000  Southampton   \n",
       "4                       Allison, Master Hudson Trevor   0.916700  Southampton   \n",
       "...                                               ...        ...          ...   \n",
       "1308                               Zakarian, Mr Artun  31.194181          NaN   \n",
       "1309                           Zakarian, Mr Maprieder  31.194181          NaN   \n",
       "1310                                  Zenn, Mr Philip  31.194181          NaN   \n",
       "1311                                    Zievens, Rene  31.194181          NaN   \n",
       "1312                                   Zimmerman, Leo  31.194181          NaN   \n",
       "\n",
       "                            home.dest room      ticket   boat     sex  \n",
       "0                        St Louis, MO  B-5  24160 L221      2  female  \n",
       "1     Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
       "2     Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male  \n",
       "3     Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
       "4     Montreal, PQ / Chesterville, ON  C22         NaN     11    male  \n",
       "...                               ...  ...         ...    ...     ...  \n",
       "1308                              NaN  NaN         NaN    NaN    male  \n",
       "1309                              NaN  NaN         NaN    NaN    male  \n",
       "1310                              NaN  NaN         NaN    NaN    male  \n",
       "1311                              NaN  NaN         NaN    NaN  female  \n",
       "1312                              NaN  NaN         NaN    NaN    male  \n",
       "\n",
       "[1313 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Algunos detalles en Python: [How to handle missing data with Python](https://machinelearningmastery.com/handle-missing-data-python/) - Jason Brownlee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preprocesamiento - Atributos categóricos\n",
    "\n",
    "- Los atributos categóricos son atributos cuyos valores pertenecen a un conjunto discreto y finito (y, a veces, no numérico) \n",
    "\n",
    "- Opción 1: Cuando tenemos $n$ etiquetas, convertir a valores enteros en el rango $[0.. n-1]$. Problema: sigue siendo discreto, e induce un orden entre las etiquetas. Lo primero puede puede perjudicar a algoritmos que asumen valores continuos, lo segundo puede no representar la realidad.\n",
    "\n",
    "- Opción 2: one-hot-encoding. Creamos tantos atributos nuevos como etiquetas diferentes haya.  En cada instancia, si el valor del atributo original es $i$, el atributo correspondiente al $i$-ésimo valor valdrá 1, y el resto valdrán 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ejemplo Titanic (cont): convertimos el atributo sex en binario (toma valores en {0,1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos un labelEncoder utilizando scikit-learn\n",
    "le=sklearn.preprocessing.LabelEncoder()\n",
    "# Obtenemos las clases a partir de los valores del conjunto de entrenamiento\n",
    "le.fit(titanic['sex'])\n",
    "# Mostramos las clases obtenidas\n",
    "le.classes_\n",
    "# Ajustamos el campo sex, transformándolo\n",
    "titanic.loc[:,'sex'] = le.transform(titanic.loc[:,'sex'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.916700</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Artun</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1310</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1311</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zenn, Mr Philip</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1312</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zievens, Rene</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1313</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row.names pclass  survived  \\\n",
       "0             1    1st         1   \n",
       "1             2    1st         0   \n",
       "2             3    1st         0   \n",
       "3             4    1st         0   \n",
       "4             5    1st         1   \n",
       "...         ...    ...       ...   \n",
       "1308       1309    3rd         0   \n",
       "1309       1310    3rd         0   \n",
       "1310       1311    3rd         0   \n",
       "1311       1312    3rd         0   \n",
       "1312       1313    3rd         0   \n",
       "\n",
       "                                                 name        age     embarked  \\\n",
       "0                        Allen, Miss Elisabeth Walton  29.000000  Southampton   \n",
       "1                         Allison, Miss Helen Loraine   2.000000  Southampton   \n",
       "2                 Allison, Mr Hudson Joshua Creighton  30.000000  Southampton   \n",
       "3     Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.000000  Southampton   \n",
       "4                       Allison, Master Hudson Trevor   0.916700  Southampton   \n",
       "...                                               ...        ...          ...   \n",
       "1308                               Zakarian, Mr Artun  31.194181          NaN   \n",
       "1309                           Zakarian, Mr Maprieder  31.194181          NaN   \n",
       "1310                                  Zenn, Mr Philip  31.194181          NaN   \n",
       "1311                                    Zievens, Rene  31.194181          NaN   \n",
       "1312                                   Zimmerman, Leo  31.194181          NaN   \n",
       "\n",
       "                            home.dest room      ticket   boat  sex  \n",
       "0                        St Louis, MO  B-5  24160 L221      2    0  \n",
       "1     Montreal, PQ / Chesterville, ON  C26         NaN    NaN    0  \n",
       "2     Montreal, PQ / Chesterville, ON  C26         NaN  (135)    1  \n",
       "3     Montreal, PQ / Chesterville, ON  C26         NaN    NaN    0  \n",
       "4     Montreal, PQ / Chesterville, ON  C22         NaN     11    1  \n",
       "...                               ...  ...         ...    ...  ...  \n",
       "1308                              NaN  NaN         NaN    NaN    1  \n",
       "1309                              NaN  NaN         NaN    NaN    1  \n",
       "1310                              NaN  NaN         NaN    NaN    1  \n",
       "1311                              NaN  NaN         NaN    NaN    0  \n",
       "1312                              NaN  NaN         NaN    NaN    1  \n",
       "\n",
       "[1313 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ejemplo titanic (cont): transformamos el campo pclass utilizando one-hot-encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['1st', '2nd', '3rd'], dtype=object)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utilizamos scikit-learn para crear un one-hot-encoder\n",
    "ohe=sklearn.preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "# Obtenemos las categorías a partir de los datos de entrenamiento\n",
    "ohe.fit(titanic['pclass'].to_numpy().reshape(-1,1))\n",
    "display(ohe.categories_)\n",
    "\n",
    "# Obtenemos los nuevos valores a partir del valor original\n",
    "new=ohe.transform(titanic['pclass'].to_numpy().reshape(-1,1))\n",
    "\n",
    "# Creamos nuevos atributos\n",
    "titanic['class_1st']=new[:,0]\n",
    "titanic['class_2nd']=new[:,1]\n",
    "titanic['class_3rd']=new[:,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "      <th>class_1st</th>\n",
       "      <th>class_2nd</th>\n",
       "      <th>class_3rd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.916700</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Artun</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1310</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1311</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zenn, Mr Philip</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1312</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zievens, Rene</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1313</td>\n",
       "      <td>3rd</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>31.194181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row.names pclass  survived  \\\n",
       "0             1    1st         1   \n",
       "1             2    1st         0   \n",
       "2             3    1st         0   \n",
       "3             4    1st         0   \n",
       "4             5    1st         1   \n",
       "...         ...    ...       ...   \n",
       "1308       1309    3rd         0   \n",
       "1309       1310    3rd         0   \n",
       "1310       1311    3rd         0   \n",
       "1311       1312    3rd         0   \n",
       "1312       1313    3rd         0   \n",
       "\n",
       "                                                 name        age     embarked  \\\n",
       "0                        Allen, Miss Elisabeth Walton  29.000000  Southampton   \n",
       "1                         Allison, Miss Helen Loraine   2.000000  Southampton   \n",
       "2                 Allison, Mr Hudson Joshua Creighton  30.000000  Southampton   \n",
       "3     Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.000000  Southampton   \n",
       "4                       Allison, Master Hudson Trevor   0.916700  Southampton   \n",
       "...                                               ...        ...          ...   \n",
       "1308                               Zakarian, Mr Artun  31.194181          NaN   \n",
       "1309                           Zakarian, Mr Maprieder  31.194181          NaN   \n",
       "1310                                  Zenn, Mr Philip  31.194181          NaN   \n",
       "1311                                    Zievens, Rene  31.194181          NaN   \n",
       "1312                                   Zimmerman, Leo  31.194181          NaN   \n",
       "\n",
       "                            home.dest room      ticket   boat  sex  class_1st  \\\n",
       "0                        St Louis, MO  B-5  24160 L221      2    0        1.0   \n",
       "1     Montreal, PQ / Chesterville, ON  C26         NaN    NaN    0        1.0   \n",
       "2     Montreal, PQ / Chesterville, ON  C26         NaN  (135)    1        1.0   \n",
       "3     Montreal, PQ / Chesterville, ON  C26         NaN    NaN    0        1.0   \n",
       "4     Montreal, PQ / Chesterville, ON  C22         NaN     11    1        1.0   \n",
       "...                               ...  ...         ...    ...  ...        ...   \n",
       "1308                              NaN  NaN         NaN    NaN    1        0.0   \n",
       "1309                              NaN  NaN         NaN    NaN    1        0.0   \n",
       "1310                              NaN  NaN         NaN    NaN    1        0.0   \n",
       "1311                              NaN  NaN         NaN    NaN    0        0.0   \n",
       "1312                              NaN  NaN         NaN    NaN    1        0.0   \n",
       "\n",
       "      class_2nd  class_3rd  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           0.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "...         ...        ...  \n",
       "1308        0.0        1.0  \n",
       "1309        0.0        1.0  \n",
       "1310        0.0        1.0  \n",
       "1311        0.0        1.0  \n",
       "1312        0.0        1.0  \n",
       "\n",
       "[1313 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ingeniería de atributos - Textos\n",
    "\n",
    "- ¿Cómo obtenemos atributos a partir de un texto? (Esto es toda un área, el Procesamiento de Lenguaje Natural)\n",
    "- Método tradicional: Bag of Words (BOW): a partir de un vocabulario (lista de palabras del lenguaje), \n",
    "construimos un vector con un atributo por palabra. Valores que toma:\n",
    "\n",
    "    - 1/0: 1 indica que la palabra existe en el texto, 0 que no. \n",
    "    - Cantidad de ocurrencias de la palabra en el texto (eventualmente normalizada, dividiendo sobre el total de palabras del documento)\n",
    "    - tf-idf: pondera la frecuencia de la palabra viendo qué tan común es en general (un valor alto indica que la palabra es común en el texto de la instancia, pero rara en el dataset).\n",
    "    \n",
    "        - $ tf  = \\frac{count}{total}$, siendo $count$ el número de ocurrencias de la palabra en el texto, y $total$ el número total de palabras en el texto\n",
    "        - $ idf = \\log\\frac{N}{n}$, siendo $N$ el número de instancias del conjunto, y $n$ el número de instancias donde la palabra aparece en el texto\n",
    "        - $tf.idf = td \\times idf$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ingeniería de atributos - Textos\n",
    "\n",
    "\n",
    "Ejercicio: supongamos que la palabra \"the\" aparece en 98 de 100 instancias, y en mi instancia aparece 10 veces (sobre un total de 200 palabras). Análogamente \"computer\" aparece 3 veces en mi texto, y en 8 de 100 instancias. Construya los vectores según los criterios descritos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ingeniería de atributos - Textos\n",
    "\n",
    "- Antes crear los vectores, es usual preprocesar el texto: dividir en tokens, eliminar palabras muy comunes (stop words), hacer lematización (buscar representantes comunes a varias palabras relacionadas). \n",
    "- El enfoque BOW no tiene en cuenta el orden de las palabras. Una mejora: utilizar n-gramas (secuencias de n palabras). A este enfoque se lo llama también bag-of-ngrams.\n",
    "\n",
    "- Recientemente se han hecho muy populares los métodos basados en word embeddings: se generan vectores densors de baja dimensionalidad (50-200 atributos), y con algunas propiedades interesantes, a partir del contexto en el que aparece cada palabra usualmente. Los métodos más conocidos son Word2Vec y Glove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Si quieren saber más sobre textos y cómo procesarlos, pueden hacer el curso [Introducción al Procesamiento del Lenguaje Natural](https://eva.fing.edu.uy/course/view.php?id=211), dictado en esta misma institución, por este mismo grupo de investigación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fase 2: División del Conjunto de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conjunto de entrenamiento, testeo, [y validación]\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1940/1*Nv2NNALuokZEcV6hYEHdGA.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "- Debemos asegurar, para evitar el sobreajuste (overfitting), que la evaluación del modelo se realice en un conjunto de datos distinto a aquel sobre el cual se entrenó. \n",
    "\n",
    "- Sobreajuste: nuestro modelo tiene buen rendimiento sobre el dataset de entrenamiento, pero sus resultados son muy inferiores cuando se encuentra a datos no vistos previamente. Causa probable: el modelo está memorizando los datos de entrenamiento, sin poder generalizar. \n",
    "\n",
    "- Si evaluamos sobre el mismo conjunto de datos sobre el que entrenamos, no podemos saber si estamos sobreajustando. **Sobreajustar es el peligro mayor cuando hacemos aprendizaje automático**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Fuente de la imagen: [About Train, Validation and Test Sets in Machine Learning](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7) - Tarang Shah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conjunto de entrenamiento, testeo, [y validación]\n",
    "\n",
    "- Separación inicial: conjunto de entrenamiento y de evalución. \n",
    "\n",
    "- Cuantas  más instancias para entrenar tengamos, probablemente mejor será nuestro modelo, PERO...\n",
    "\n",
    "- Cuantas más intancias para evaluar tengamos, menor será la varianza de nuestros resultados.\n",
    "\n",
    "- Usualmente se divide como 80%-20%, o 70%-30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conjunto de validación\n",
    "\n",
    "- Si queremos ajustar los parámetros del modelo (lo veremos en breve), no es conveniente hacerlo en el conjunto de evaluación (ya que podríamos estar sobreajustando, nuevamente). \n",
    "\n",
    "- Opción 1: separar una parte del conjunto de entrenamiento para utilizarlo en esa etapa\n",
    "\n",
    "- Opción 2: utilizar validación cruzada (cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fase 3: Entrenamiento\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_workflow.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Entrenamiento\n",
    "\n",
    "- Durante el entrenamiento, utilizamos los datos del conjunto de entrenamiento, y un algoritmo de aprendizaje, para generar un clasificador.\n",
    "\n",
    "- Una vez generado el modelo, lo evaluamos en el conjunto de evaluación para obtener una medida de su performance (veremos más adelante las principales medidas utilizadas).\n",
    "\n",
    "- Los algoritmos de entrenamiento tienen usualmente hiperparámetros que deberían ajustarse (e.g. profundidad máxima de un árbol en los árboles decisión). Usualmente lo que se hace es probar diferentes valores para cada parámetro y ver cuál obtiene mejores resultados. Como no queremos hacer esto sobre el corpus de evaluación (¿por qué?), utilizamos un subconjunto del corpus de entrenamiento, el corpus de validación (o corpus held-out). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estratificación\n",
    "\n",
    "- Aunque no queremos que la evaluación se realice en el conjunto de entrenamiento, sí nos interesa que la distribución de los ejemplos en uno y otro sea similar.\n",
    "\n",
    "- Al hacer la división de los conjuntos, lo usual es elegir las instancias al azar, para evitar que las agrupaciones u ordenamientos presentes en el conjunto original puedan dar lugar a distribuciones distintas. (Por ejemplo, ¿qué sucedería si, para predecir supervivencia,  entrenamos sobre las pasajeras mujeres en la lista del Titanic, y evaluamos sobre los hombres?).\n",
    "\n",
    "- Un paso más, especialmente importante cuando las clases objetivo están _desbalanceadas_ (es decir, hay muchos más ejemplos de una clase que de otras), es estratificar: elegir las instancias en cada una de las subclases, obligando a que la proporción sea la misma en el corpus de entrenamiento y en el de evaluación.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Stratified_sampling.PNG/440px-Stratified_sampling.PNG\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Validación cruzada y selección de modelos\n",
    "\n",
    "- Para utilizar mejor el corpus de entrenamiento y no tener que separar datos para validación, una alternativa es realizar validación cruzada. Este método, además, permite disminuir la varianza de los resultados (ya que se obtiene como el promedio de varias evaluaciones), aunque es más costoso en términos de tiempo de entrenamiento.\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Validación cruzada y selección de modelos\n",
    "\n",
    "\n",
    "- En la validación cruzada, se divide el dataset de entrenamiento en k partes, y se utilizan (k-1) partes para entrenar, y la restante para evaluar el modelo. Este proceso se repite cambiando la parte elegida. \n",
    "\n",
    "- Se devuelve el promedio del valor de performance obtenido, y también la desviación estándar de los resultados.\n",
    "\n",
    "<img src=\"http://ethen8181.github.io/machine-learning/model_selection/img/kfolds.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Fuente de las imágenes anteriores y lectura recomendada: [Cross-validation: evaluating estimator performance¶](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estandarización de atributos\n",
    "\n",
    "- Muchos algoritmos en aprendizaje automático (e.g. knn, redes neuronales, PCA) se benefician de que los atributos continuos tengan aproximadamente el mismo orden de magnitud. Esto se debe, por ejemplo, a que se utiliza la distancia euclidiana y se busca que todos los atributos \"pesen\" igual al calcularla. En el caso de algoritmos que utilizan descenso por gradiente, puede haber mucha diferencia en performance. \n",
    "\n",
    "- Min-max scaling: este escalado deja los valores en el rango $[0-1]$. Dado un valor $x$, obtenemos:\n",
    "\n",
    "    $ x_s = \\frac{x - x_{min}}{x_{max} - x_{min}}$\n",
    "    \n",
    "    siendo $x_{min}$ y $x_{max}$ los valores mínimo y máximo respectivamente en el dataset\n",
    "    \n",
    "- Normalización: se escalan los atributos para que tengan las propiedades de una distribución normal estándar, con $\\mu = 0$ y $\\sigma = 1$. \n",
    "\n",
    "    $ x_{norm} = \\frac{x_i - \\mu_{i}}{s_i} $\n",
    "    \n",
    "    siendo $\\mu_{i}$ la media y  $s_i$ la desviación estándar de la muestra.\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ejercicio: normalice los siguientes valores utilizando los dos métodos anteriores: $\\{85,35,42,8,15, 22\\}$. ¿En qué rango quedan los valores obtenidos por normalización?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mínimo: 8\n",
      "Valor máximo: 85\n",
      "Valores escalados min-max: [1.   0.35 0.44 0.   0.09 0.18]\n",
      "Valor medio: 34.50\n",
      "Desviación estándar: 25.32\n",
      "Valores normalizados: [ 1.99  0.02  0.3  -1.05 -0.77 -0.49]\n",
      "Media del nuevo vector:0.00 / Desviación estándar:1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "x=np.array([85,35,42,8,15,22])\n",
    "\n",
    "# Min-max scaling\n",
    "min_x=min(x); max_x=max(x)\n",
    "print (\"Valor mínimo: {0}\".format(min_x))\n",
    "print (\"Valor máximo: {0}\".format(max_x))\n",
    "\n",
    "x_s = (x-min_x)/(max_x- min_x)\n",
    "print (\"Valores escalados min-max: {0}\".format(x_s))\n",
    "\n",
    "# Normalización\n",
    "# Existe np.mean(x), pero hagamos más explícita la cuenta\n",
    "media_x=np.sum(x)/x.size\n",
    "print (\"Valor medio: {:0.2f}\".format(media_x))\n",
    "\n",
    "# Calculo la desviación estándar. Existe np.std(x), pero lo hacemos a mano\n",
    "std_x = np.sqrt(np.mean((x - media_x)**2))\n",
    "print (\"Desviación estándar: {:0.2f}\".format(std_x))\n",
    "x_n = (x - media_x)/std_x\n",
    "print (\"Valores normalizados: {}\".format(x_n))\n",
    "# Verificamos que el vector ahora tiene media 0 y desviación estándar 1\n",
    "print(\"Media del nuevo vector:{:0.2f} / Desviación estándar:{:0.2f}\".format(np.mean(x_n), np.std(x_n)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Lectura: [About standarization](https://sebastianraschka.com/Articles/2014_about_feature_scaling.html) - Sebastian Rashcka\n",
    "- Nota: la estandarización, así como la selección de los atributos, debe hacerse durante el entrenamiento (no antes). Por eso la incluimos en esta fase, aunque en muchos contextos se lo presenta como previo al aprendizaje. Véase [este link](https://stats.stackexchange.com/questions/77350/perform-feature-normalization-before-or-within-model-validation) por más detalles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Selección de atributos\n",
    "\n",
    "- Luego de que tenemos atributos \"candidatos\", nos gustaría quedarnos con aquellos que \"valen la pena\" para la tarea de clasificación que intentamos hacer. No hay una definición obvia de \"vale la pena\", pero nos interesan (para evitar ruido, y también por razones de eficiencia computacional) aquellos atributos que, en conjunto, sirvan para mejorar nuestra predicción. \n",
    "\n",
    "- El objetivo de la selección de atributos es eliminar atributos que son irrelevantes o redundantes. Por ejemplo: si tenemos dos atributos con valores idénticos, podemos eliminar uno de ellos. O si un atributo tiene siempre el mismo valor. O, por el contrario, todos sus valores son diferentes (en este caso, servirá como predictor perfecto de la clase objetivo si lo memorizamos, pero seguramente su capacidad de generalización será nula).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Selección de atributos - Métodos de filtrado\n",
    "\n",
    "- Este tipo de métodos intentan evaluar (por separado) qué tan bueno es cada atributo. \n",
    "\n",
    "- Una forma muy básica: seleccionar los atributos que superan cierto valor de varianza. Se basa en la idea de que los atributos que valen siempre lo mismo seguramente no sean buenos predictores. Defecto: no utilizan la clase objetivo.  \n",
    "\n",
    "- $ \\chi^2$ (chi-squared): cuando tenemos dos variables categóricas, podemos utilizar este método para saber, a partir de los valores observadores y los esperados, si las dos variables son independientes. Cuanto mayor es el valor, mayor su correlación. Por lo tanto, podemos utilizar esta medida para obtener los atributos más correlacionados con la clase objetivo (y que, por lo tanto, deberían ser mejores predictores).\n",
    "\n",
    "\n",
    "- Ganancia de información: la ganancia de información, o información mutua de dos variables aleatorias es una medida (proveniente de la teoría de la información) que indica qué tanto podemos saber de una de allas conociendo la otra, es decir qué tan dependientes son entre sí. Vale 0 sí y solo sí ambas variables son independientes. Por lo tanto, esta medida puede ser utilizada en forma análoga al test $ \\chi^2$ para eliminar atributos independientes de la clase objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Selección de atributos - Métodos _wrappers_\n",
    "\n",
    "- Este tipo de métodos de selección utilizan un método de aprendizaje para evaluar diferentes combinaciones de atributos y seleccionar la que obtenga mejores resultados sobre un dataset heldout separado, o vía cross-validation. Para que funcionen, el método debe ser capaz de asignar un valor de importancia a cada atributo, luego de entrenado el modelo. \n",
    "\n",
    "- Por ejemplo, el método de **eliminación recursiva de atributos** parte del conjunto inicial de atributos y, aplicando un método de aprendizaje (por ejemplo, árboles de decisión) sobre un conjunto de validación, elimina aquellos atributos menos importantes. Se repite el proceso hasta llegar a un cierto número de atributos deseados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Selección de atributos - Métodos _embedded_\n",
    "\n",
    "- A diferencia de los anteriores, la selección de atributos es realizada por el mismo algoritmo de aprendizaje, durante el proceso de entrenamiento.\n",
    "\n",
    "- Un ejemplo ya visto en el curso es el de la selección de atributos que realizan los árboles de decisión.\n",
    "\n",
    "- Otro ejemplo, que veremos más adelante en el curso, son los métodos de regularización, que buscan generar modelos más \"sencillos\", para evitar el sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Lectura: [An Introduction to Feature Selection](https://machinelearningmastery.com/an-introduction-to-feature-selection/) - Jason Brownlee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fase 4: Evaluación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- El paso final es evaluar la performance del modelo (clasificador) obtenido sobre un conjunto de datos no vistos previamente. Hasta ahora, no hemos dicho cómo medimos esa performance\n",
    "\n",
    "- Imaginemos un clasificador binario. \n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/clasificador.PNG\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accuracy\n",
    "\n",
    "- Lo más sencillo es estimar el acierto (accuracy) o el error.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/accuracy.PNG\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "$$ acc = \\frac{V_{azul} + V_{amarillo}}{V_{azul}+V_{amarillo} + F_{azul}+F_{amarillo}}$$  \n",
    "\n",
    "$$ error = \\frac{F_{azul} + F_{amarillo}}{V_{azul}+V_{amarillo} + F_{azul}+F_{amarillo}} = 1 - acc $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precisión y Recuperación\n",
    "\n",
    "- El problema con el acierto y el error es que no tienen en cuenta el\n",
    "comportamiento en las distintas clases.\n",
    "- Si el 99% de las instancias son azules, la función constante azul tiene\n",
    "un acierto de 99%.\n",
    "- Se buscan alternativas para medir por clase: precisión, recuperación (_recall_)\n",
    "\n",
    "\n",
    "$$ precision = \\frac{V_p} {V_p + F_p} $$\n",
    "\n",
    "$$ recall = \\frac{V_p}  {V_p+F_n} $$\n",
    "\n",
    " \n",
    "\n",
    "$V_p$ indica verdaderos positivos, es decir aquellos ejemplos que fueron clasificados correctamente\n",
    "\n",
    "$F_p$ indica falsos positivos, es decir aquellos ejemplos que fueron clasificados como positivos, pero eran negativos\n",
    "\n",
    "$V_n$ indica verdaderos negativos\n",
    "\n",
    "$F_n$ indica falsos negativos \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precisión y Recuperación\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg\" alt=\"Drawing\" style=\"width: 220px;\"/>\n",
    "\n",
    "\n",
    "- La precision mide qué tan bueno es el clasificador cuando dice que un ejemplo es positivo\n",
    "\n",
    "- La recuperación mide qué proporción encuentra de los positivos existentes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Medida-F\n",
    "- Combinando precisión y recuperación se obtiene la medida-F (donde $\\beta$ indica cuánta más importancia se le da al recall respecto a la precisión) : \n",
    "\n",
    "$$F_\\beta = \\frac{(1+ \\beta^2) \\cdot  precision \\cdot recall}{\\beta^2 \\cdot precision + recall}$$\n",
    "\n",
    "- En el caso de $F_1$, la formula queda reducida a:\n",
    "\n",
    "$$F_1 = \\frac{2 \\cdot  precision \\cdot recall}{ precision + recall}$$\n",
    "\n",
    "- La medida-F es la media armónica entre precisión y recall, e intenta combinar ambas en un sólo número. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Para una interesante discusión sobre por qué se utiliza la media armónica y no la media aritmética, sugerimos este artículo: [The truth of the F-measure](https://www.cs.odu.edu/~mukka/cs795sum09dm/Lecturenotes/Day3/F-measure-YS-26Oct07.pdf) - Yutaka Sasaki\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Medida-F\n",
    "\n",
    "\n",
    "Ejercicio: complete la siguiente tabla, para una clasificación sobre 100.000 instancias\n",
    "\n",
    "\n",
    "| $V_p$ | $F_p$ | $F_n$ | $V_n$ | Prec | Recall | $F_1$ | Accuracy |\n",
    "| :---: |:---:  | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| 25    |   0   | 125   | 99850 |  |   |  | |\n",
    "| 50    |  100   | 100   | 99750 |   |  |  |  |\n",
    "| 75    |   150   | 75   | 99700 |  |  |  |  |\n",
    "| 100    |   50  | 50  | 99800 |  |  |  |  |\n",
    "| 150    |   100   | 0   | 99750 |  |  |  |  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Medida-F\n",
    "\n",
    "\n",
    "Ejercicio: complete la siguiente tabla, para una clasificación sobre 100.000 instancias\n",
    "\n",
    "\n",
    "| $V_p$ | $F_p$ | $F_n$ | $V_n$ | Prec | Recall | $F_1$ | Accuracy |\n",
    "| :---: |:---:  | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| 25    |   0   | 125   | 99850 | 1.00 | 0.17  | 0.29 | 0.999    |\n",
    "| 50    |  100   | 100   | 99750 |0.33 | 0.33 |0.33 |0.999  | \n",
    "| 75    |   150   | 75   | 99700 | 0.33 | 0.50|0.40|0.998 |  \n",
    "| 100    |   50  | 50  | 99800 | 0.67 | 0.67|0.67|0.999  |\n",
    "| 150    |   100   | 0   | 99750 | 0.60 |1.00| 0.75| 0.999 |\n",
    "\n",
    "- ¿Qué sucede con la accuracy? ¿Y con los otros valores? ¿Cuál de los clasificadores eligiría?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problemas multiclase\n",
    "\n",
    "- ¿Qué sucede cuando se tiene un problema multiclase (es decir, hay más de dos categorías)?\n",
    "- Las medidas anteriores siguen valiendo, si consideramos como \"positivos\" a las instancias que pertenecen a una clase, y \"negativos\" al resto (one-versus-all).\n",
    "\n",
    "- Esto nos da una medida por cada clase. Existen diferentes formas de resumir esa información:\n",
    "\n",
    "    Se calcula la medida por clase, y luego se promedia los valores obtenidos (macro average)\n",
    "    \n",
    "    Se calcula la medida por clase teniendo en cuenta el aporte de instancias cada clase (micro average)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problemas multiclase\n",
    "\n",
    "\n",
    "- Por ejemplo, supongamos que queremos calcular precisión para la siguiente tabla:\n",
    "\n",
    "| Clase | $V_p$ | $F_p$ | Prec |\n",
    "| --- |:---:  | :---: | :---: |\n",
    "| A   |   1   | 1   | 0.5 | \n",
    "| B    |  10   | 90   | 0.1 |\n",
    "| C    |   1   | 1   | 0.5 |\n",
    "| D    |   1  | 1  | 0.5 |\n",
    "\n",
    "- La macro-average será $ \\frac{0.5+0.5+0.1+0.5}{4} = 0.4 $\n",
    "- La micro-average será $ \\frac{1+10+1+1}{2+100+2+2} = 0.22 $\n",
    "\n",
    "- Puede verse que la micro-average es menor, porque lo mal que nos fue en la clase B hace que el promedio baje, porque es una clase mucho más grande que las demás.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Lectura recomendada: [Micro Average vs Macro average Performance in a Multiclass classification setting](https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problemas multietiqueta\n",
    "\n",
    "\n",
    "- En un problema multietiqueta, hay más de una clase asociada a cada etiqueta, como en el siguiente ejemplo\n",
    "\n",
    "| Instancia | Clase | Predicción |\n",
    "| --- |:---:  | :---: | \n",
    "| 1   | A,B   | B,C | \n",
    "| 2    | A,B,C   | A,C,D |\n",
    "| 3    | A,B   | A,B |\n",
    "\n",
    "- Se pueden calcular las medidas utilizando solamente los ejemplos de cada clase, sin importar el resto. Esto permite utilizar las medidas mencionadas anteriormente\n",
    "\n",
    "- Se pueden aplicar otras medidas, como promediar el índice de Jaccard $IJ(A,B) = |A \\cap B| / |A \\cup B|$\n",
    "\n",
    "- En el ejemplo, $IJ(1)=1/3$, $IJ(2)=1/2$, $IJ(3)=1$, y por lo tanto el índice de Jaccard promedio será $0.61$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matriz de confusión\n",
    "\n",
    "- Una forma muy útil para intentar entender el comportamiento del clasificador, especialmente cuando se tiene más de dos clases. \n",
    "\n",
    "- Las filas de la matriz representan las instancias pertenecientes en el conjunto a cada clase, mientras que las columnas indican cómo fueron clasificadas por mi modelo.\n",
    "\n",
    "- Cada celda se lee como \"X elementos de la clase {fila} fueron clasificados como {columna}\n",
    "\n",
    "- En la diagonal quedan los elementos correctamente clasificados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matriz de confusión\n",
    "\n",
    "En el siguiente ejemplo (tomado de [aquí](https://www.blackhc.net/blog/2019/mnist-by-zip/)), se muestra una matriz de confusión para un clasificador de dígitos escritos a mano (que no funciona muy bien, dicho sea de paso...). En este caso, los valores fueron normalizados, esto es, varían entre 0 y 1 (¿imagina para qué?)\n",
    "\n",
    "<img src=\"https://www.blackhc.net/blog/2019/mnist-by-zip/confusion_matrix_45.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Línea base  y línea máxima\n",
    "\n",
    "- ¿Cómo sabemos si el resultado que obtuvimos es \"bueno\", o \"razonable\"?\n",
    "\n",
    "- El resultado depende del problema. \n",
    "\n",
    "- Siempre es bueno tener una línea base: una solución anterior sencilla, o un clasificador que elige siempre la clase más probable o según la distribución del conjunto de entrenamiento\n",
    "\n",
    "- También es útil (si es posible) tener una línea de tope, sobre todo en problemas donde no hay antecedentes. Típicamente, se pide a humanos que actúen como clasificadores y se evalúa su performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ¿Preguntas?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
