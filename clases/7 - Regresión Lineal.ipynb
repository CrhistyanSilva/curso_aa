{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regresión Lineal\n",
    "### Aprendizaje Automático - Instituto de Computación - UdelaR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "En este módulo presentaremos dos métodos de aprendizaje supervisado: la regresión lineal, y el método de clasificación llamado regresión logística. Está basado fundamentalmente en las [notas del curso CS229](http://cs229.stanford.edu/notes/cs229-notes1.pdf) de la Universidad de Stanford, y de las presentaciones y material asociadas (disponibles a través de la plataforma Coursera). Sugerimos recurrir a ambas fuentes para más detalles respecto a los métodos aquí presentados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regresión Lineal\n",
    "\n",
    "La regresión lineal es una forma de aprendizaje supervisado donde, a partir de un vector $x^T = (x_1, x_2, \\ldots, x_n)$ con $n$ _atributos_ (o *variables*) se busca construir una función (hipótesis) $h_{\\theta}(x): \\mathbb{R}^{n} \\to \\mathbb{R}$ que prediga la salida $y \\in \\mathbb{R}$ (llamada *variable o atributo de salida*), continua,  a través del siguiente modelo:\n",
    "\n",
    "$$h_{\\theta}(x) = \\theta_0+\\sum_{j=1}^n x_j\\theta_j$$\n",
    "\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Mauricio_Salgado/publication/42100369/figure/fig1/AS:652249911001105@1532519905539/Figura-1-modelo-de-regresion-Lineal-expectativa-de-vida-al-nacer-y-PiB-per-capita-por.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regresión Lineal\n",
    "\n",
    "A los elementos del vector $\\theta$ se lo conoce como _parámetros_ (también llamados *pesos*). Al término $\\theta_0$ se le llama *sesgo*. Podemos expresar el modelo de forma más compacta como un producto interno de vectores:\n",
    "\n",
    "$$h_{\\theta}(x)= \\theta_0 + x^T\\theta$$ \n",
    "\n",
    "\n",
    "Es común agregar una constante 1 al vector $x$, y agregar $\\theta_0$ a $\\theta$, expresando entonces el modelo de una forma más compacta aún:\n",
    "\n",
    "$$h_{\\theta}(x)= x^T\\theta$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regresión Lineal\n",
    "\n",
    "El problema de aprendizaje para la regresión lineal multivariada consiste en **aprender los parámetros $\\theta$** a partir de un conjunto de entrenamiento $\\{(x^{(i)},y^{(i)})\\}$ que tiene $m$ elementos y donde cada $(x^{(i)},y^{(i)})$ es una _instancia_ de entrenamiento. Para esto, deberemos definir una función de costo que nos diga qué tan parecido es el valor predicho por $h_{\\theta}(x^{(i)})$ al verdadero valor de $y^{(i)}$ en el conjunto de entrenamiento. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consideremos, por ejemplo, al \"Abalone dataset\" (un conjunto de datos que tiene como valores de entrada ciertas medidas de la caparazón de un molusco, y como salida el número de anillos):\n",
    "\n",
    "| Largo|  Diámetro|  Altura|  Peso|  Anillos| \n",
    "| ------: |---:| -----:|---:|---:|\n",
    "| 0.455| 0.365| 0.095| 0.514| 15| \n",
    "| 0.35| 0.265| 0.09| 0.2255| 7| \n",
    "| 0.53| 0.42| 0.135| 0.677| 9| \n",
    "| 0.44| 0.365| 0.125| 0.516| 10| \n",
    "| 0.33| 0.255| 0.08| 0.205| 7| \n",
    "\n",
    "En este caso, el atributo \"Largo\" corresponde a $x_1$, \"Diámetro\" a $x_2$, y así sucesivamente. La instancia $(x^{(3)},y^{(3)})$, por ejemplo corresponde a $([1,0.53,0.42,0.135,0.677], 9)$, y por lo tanto $\\theta \\in \\mathbb{R}^5$. El problema de aprendizaje, en este caso, consiste en obtener, a partir de un conjunto de entrenamiento, un conjunto de valores para los elementos de $\\theta$, que permitan predecir, para nuevas instancias de $x$, su valor $y$ asociado, con tanta precisión como sea posible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Método de Aproximación por  Mínimos Cuadrados (Least Squares)\n",
    "\n",
    "Una método para estimar $\\theta$ es buscar aquellos valores que hagan que $h_\\theta(x)$ sea tan cercano a $y$ como sea posible, para las instancias de entrenamiento que contamos. Para esto, definiremos una *función de costo*, que mide esta diferencia, y que será la que intentemos minimizar. \n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b0/Linear_least_squares_example2.svg\" align=\"center\" alt=\"Drawing\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Esta función (llamada de mínimos cuadrados), mide la diferencia entre cada valor de $y$ y el valor predicho por $h_\\theta(x)$, para la instancia $x$ correspondiente, calcula su cuadrado (esto hace que siempre dé positivo), y hace la suma en todos los ejemplos de entrenamiento. La constante $\\frac{1}{2m}$ no afecta el resultado final... y hace más fáciles algunas cuentas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**¿Cuál es la función de costo para el Dataset Abalone?**\n",
    "\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{10} ( (x^{(1)})^T \\theta - y^{(1)})^2 + ((x^{(2)})^T \\theta - y^{(2)})^2 + \\ldots $$\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{10} ( (\\theta_0 + 0.455\\theta_1 + 0.365\\theta_2 + \\ldots - 15)^2 + (\\theta_0 + 0.35\\theta_1 + 0.265\\theta_2 + \\ldots - 7)^2  + \\ldots $$\n",
    "\n",
    "Obsérvese que J es una función de $\\theta$, no de $x$. Cuando decimos que hacemos regresión *lineal* es porque los coeficientes $\\theta$ se combinan por una función lineal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Desde un punto de vista probabilistíco, la minimización de la función de mínimos cuadrados corresponde a encontrar, bajo ciertas condiciones, los estimadores de máxima verosimilitud (es decir, más adecuados al conjunto de entrenamiento) para $\\theta$. La justificación excede el alcance de este curso, pero vale mencionarlo para comenzar a formalizar la idea de que la elección de esta función de costo es, al menos, \"razonable\". \n",
    "\n",
    "Esta forma de aproximación a una hipótesis es una función lineal de los parámetros, se lo conoce como mínimos cuadrados lineal u ordinario (Ordinary Least Squares, o OLS). Existen versiones no lineales para la regresión, que no cubriremos en este curso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ecuaciones Normales\n",
    "\n",
    "El objetivo, entonces, es obtener los valores de $\\theta$ que minimicen la función de costo $J(\\theta)$. La primera forma que veremos es directamente calcular las derivadas respecto a los diferentes $\\theta_j$ e igualarlas a 0 (al ser $J$ una función cuadrática, es también convexa, y por lo tanto solamente tiene un mínimo global, que coincide con el punto donde su gradiente  $\\nabla_\\theta$ es 0). \n",
    "\n",
    "Para esto, vamos primero a escribir $J$ en forma vectorial. Dado un conjunto de entrenamiento con $n$ atributos y $m$ instancias, definiremos la matriz de diseño $X \\in \\mathbb{R}^{m \\times (n+1)}$, como aquella que tiene las instancias de entrenamiento en sus filas, y al vector columna $y$ que tiene en cada fila el valor correspondiente de $y^{(i)}$. Puede verse que, con esta formulación, llegamos a:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m}(X\\theta-y)^T(X\\theta -y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ecuaciones Normales\n",
    "\n",
    "Utilizando propiedades de la traza de una matriz y sus gradientes, podemos llegar a un valor de $\\nabla_\\theta J(\\theta)$ (por el detalle de la derivación, consúltese las referencias):\n",
    "\n",
    "$$ \\nabla_\\theta J(\\theta) = X^TX\\theta - X^Ty $$\n",
    "\n",
    "Igualando el gradiente a 0, obtenemos las ecuaciones normales:\n",
    "\n",
    "$$ X^TX\\theta = X^Ty$$\n",
    "\n",
    "y por lo tanto el valor de $\\theta$ que minimiza $J(\\theta)$ estará dado por:\n",
    "\n",
    "$$ \\theta = (X^TX)^{-1}X^Ty$$\n",
    "\n",
    "Las ecuaciones normales proveen una forma cerrada de calcular los valores de $\\theta$ que minimizan $J(\\theta)$. El algoritmo asociado tiene $O(n^3)$, por lo que si el número de atributos o de instancias es muy grande, puede llegar a ser muy lento, y, en esos casos, es preferible utilizar métodos iterativos, como el que veremos a continuación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Descenso por gradiente\n",
    "\n",
    "El algoritmo de _descenso por gradiente_ es una aproximación completamente diferente a la minimización de $J(\\theta)$. Es un algoritmo de búsqueda iterativo, que parte de una estimación inicial de $\\theta$, y la va cambiando para que $J(\\theta)$ se reduzca, hasta converger a un valor de $\\theta$ que corresponde a un mínimo global de $J(\\theta)$, **siempre y cuando $J(\\theta)$ sea convexa**.\n",
    "\n",
    "El algoritmo comienza con un $\\theta$ inicial, y repetidamente realiza la siguiente actualización (simultáneamente para todos los $\\theta_j$, con $j = 0,\\ldots,n$):\n",
    "\n",
    "\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta) $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Descenso por gradiente\n",
    "\n",
    "\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta) $$\n",
    "\n",
    "\n",
    " $f:\\mathbb{R}\\to \\mathbb{R}$           |  $f:\\mathbb{R^2}\\to \\mathbb{R}$  \n",
    ":-------------------------:|:-------------------------:\n",
    "![](https://ml-cheatsheet.readthedocs.io/en/latest/_images/gradient_descent_demystified.png)  |  ![](https://st4.ning.com/topology/rest/1.0/file/get/3713179836?profile=original)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Descenso por gradiente\n",
    "\n",
    "\n",
    "La función de mínimos cuadrados es convexa, por lo tenemos la garantía de que el descenso por gradiente convergerá a un mínimo global. Para el caso de la minimización de la función de mínimos cuadrados, podemos hacer explícito el valor de $\\frac{\\partial}{\\partial \\theta_j}J(\\theta)$, a partir de su definición:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " \\frac{\\partial}{\\partial \\theta_j}J(\\theta)&=& \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y{(i)})^2 \\\\\n",
    " &=& \\frac{1}{2m}\\sum_{i=1}^{m} 2 \\cdot (h_\\theta(x^{(i)}) - y^{(i)})\\cdot \\frac{\\partial}{\\partial \\theta_j} (h_\\theta(x^{(i)}) - y^{(i)})\\\\\n",
    "&=& \\frac{1}{m}\\sum_{i=1}^{m}  (h_\\theta(x^{(i)}) - y^{(i)})\\cdot \\frac{\\partial}{\\partial \\theta_j} (\\sum_{p=0}^{n} \\theta_p x_p^{i} - y^{(i)})\\\\ \n",
    "&=& \\frac{1}{m}\\sum_{i=1}^{m}  (h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j\\\\ \n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Descenso por gradiente\n",
    "\n",
    "\n",
    "Y, por lo tanto, la regla de actualización (simultánea para todos los $\\theta_j$) será:\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{1}{m}\\sum_{i=1}^{m}  (h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j   $$\n",
    "\n",
    "Esta regla (llamada LMS o de Widrow-Hoff) hace que la actualización de los valores de los parámetros $\\theta$ sea proporcional al error promedio cometido por la hipótesis actual, y en la dirección del gradiente (con el sentido opuesto). El algoritmo de _descenso por gradiente batch_ consiste en aplicar esta regla repetidamente, hasta lograr la convergencia (que podría definirse, por ejemplo, cuando $J(\\theta)$ queda por debajo de cierto valor $\\epsilon$).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta, iterations, alpha):\n",
    "    for i in range(iterations):\n",
    "        prediction = np.dot(x, theta)\n",
    "        error = prediction - y\n",
    "        cost = 1/(2*m) * np.dot(error.T, error)\n",
    "        theta = theta - (alpha * (1/m) * np.dot(x.T, error))\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Descenso por gradiente estocástico (o incremental)\n",
    "\n",
    "Puede verse que en este caso, para cada iteración se calcula el error cometido por la hipótesis sobre todas las instancias de entrenamiento. Una alternativa es actualizar los valores de $\\theta$ luego de calcular el error sobre cada ejemplo del conjunto de entrenamiento:\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha (h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j   \\text{   (simultáneamente para todos los $j$)} $$ \n",
    "\n",
    "En este caso, aunque el algoritmo no garantiza converger al mínimo, tiene la ventaja de hacerlo más rápido que la versión batch. Esta versión del algoritmo es conocida como *descenso por gradiente estocástico o incremental*, y se utiliza especialmente en los casos en los que $m$ (es decir, la cantidad de instancias de entrenamiento) es muy grande.\n",
    "\n",
    "\n",
    "Para lograr un compromiso entre el descenso por gradiente batch (que utiliza todos los ejemplos en cada iteración) y el incremental (que utiliza un ejemplo en cada iteración), es común procesar, en cada iteración un conjunto $m$  instancias (e.g. 512 o 1024). Esto tiene la ventaja computacional adicional de que pueden ser vectorizados y procesados en paralelo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regresión Polinomial\n",
    "\n",
    "Si bien la función $h_\\theta(x)$ es lineal respecto a los valores de sus atributos, esto no quiere decir que tenga que ser necesariamente una recta respecto a los valores de entrada. La razón es que es posible definir atributos que sean combinaciones de los de entrada, como $x_1^2$ o $x_1x_2$, con los que la función $h_\\theta(x)$ será polinomial respecto a los atributos de entrada originales. \n",
    "\n",
    "Por ejemplo, nuestra hipótesis para regresión polinomial podría ser \n",
    "\n",
    "\n",
    "$$h_{\\theta}(x) = \\theta_0+ x_1\\theta_1 + x_2\\theta_2 + x_1x_2\\theta_3 + x_1^2\\theta_4 $$\n",
    "\n",
    "\n",
    "Nota importante: aunque parezca contradictorio, la regresión polinomial sigue siendo un problema de aproximación... lineal (la relación polinomial está dada entre $y$ y $x$, pero sigue siendo una combinación lineal de los parámetros). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "La selección de estos atributos no es trivial, y dependerá del conocimiento del problema que tiene quien elabora la regresión. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Descenso por Gradiente en la práctica\n",
    "\n",
    "Para poder aplicar descenso por gradiente de forma efectiva, deben tenerse algunos aspectos en cuenta:\n",
    "\n",
    "- **Selección de $\\alpha$ y criterio de convergencia**\n",
    "\n",
    "La constante $\\alpha$ que aparecen en la regla de Widrow-Hoff indica el tamaño del paso de reducción de $\\theta$ en la dirección indicada por el gradiente calculado. Cuanto más grande sea, más rápida será la convergencia. Sin embargo, si $\\alpha$ es demasiado grande, podemos dar un paso que haga que nos \"pasemos\"en nuestra aproximación al mínimo y que  el valor de $J(\\theta)$ comience a oscilar, o incluso a diverger (obsérvese que cada paso es proporcional a $\\alpha$, _pero también_ a la variable de entrada correspondiente). \n",
    "\n",
    "Una forma de ajustar $\\alpha$ es graficar $J(\\theta)$ versus el número de iteraciones del algoritmo: si el $\\alpha$ es adecuado, la convergencia debería ser rápida y el descenso de $J$ constante. Si no se da el primer caso, $\\alpha$ debería incrementarse. Si no se da el segundo ($J$ crece u oscila), $\\alpha$ debería reducirse.\n",
    "\n",
    "Es muy común también ir reduciendo el valor de $\\alpha$ a medida que avanzan las iteraciones (y supuestamente nos acercamos al mínimo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Descenso por Gradiente en la práctica\n",
    "\n",
    "\n",
    "- **Normalización de la media**\n",
    "\n",
    "Cuando los diferentes atributos tienen valores en rangos muy diferentes, el descenso por gradiente convergerá más lentamente, porque $\\theta$ se reducirá mucho en los rangos más pequeños, pero poco en los grandes. Para evitar esto, lo usual es llevar los atributos de entrada a valores en los mismos rangos. \n",
    "El método usual es la normalización: se resta a cada valor de un atributo de entrada el valor medio de ese atributo en el conjunto de entrenamiento, y se divide por la desviación estándar de los valores, haciendo que los valores queden con media 0 y desviación estándar igual a la de la muestra. La fórmula para ajustar cada atributo de la entrada es:\n",
    "\n",
    "$$\n",
    "x_i = \\frac{x_i - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "siendo $\\mu$ la media y $\\sigma$ la desviación estándar de los valores del atributo considerado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularización\n",
    "\n",
    "En el caso de la regresión lineal, el sobreajuste podría hacer que la función $h_\\theta(x)$ sea muy compleja (por ejemplo, porque aparecen atributos de orden polinomial alto), y ajuste demasiado a los datos de entrenamiento, perdiendo capacidad de generalización. Una técnica usual (y que no solamente aplica para este método), es la de la *regularización*: se agrega un componente a la función de costo que busca penalizar cierto tipo de funciones. En el caso de la regresión lineal, nuestra función de costo queda de la siguiente forma:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\left [ \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j=1}^n  \\theta_j^2 \\right ] $$\n",
    "\n",
    "Esta forma de regresión se conoce también como $Ridge$, y busca penalizar valores grandes de los parámetros.\n",
    "\n",
    "El parámetro $\\lambda$ cumple un rol muy importante: si es muy grande, el peso de tener una hipótesis \"simple\" (y por lo tanto nuestro sesgo) es mayor, mientras que si tiende a cero, intentaremos buscar hipótesis que se ajusten mejor a los datos de entrenamiento (aunque la varianza aumente). Por lo tanto, si $\\lambda$ es $0$, nuestro riesgo de sobreajuste es máximo, mientras que si $\\lambda$ tiende a infinito, entonces es probable que suframos de _underfitting_: nuestras hipótesis son tan sencillas que ajustaran mal incluso a los datos de entrenamiento. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "La regresión agrega sesgo a nuestra hipótesis, para lograr menos varianza, y que pequeñas variaciones en los atributos de entrada no impliquen grandes cambios en la salida. En el caso de Ridge, buscar resolver el problema de que, cuando los valores de algún $\\theta_j$ son muy grandes, pequeños cambios en la correspondiente variable $x_j$ producirán grandes cambios en el valor de $h_\\theta(x)$, haciendo que $h$ sea más proclive al sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularización\n",
    "\n",
    "Aplicando el mismo procedimiento que cuando definimos la regla de actualización original, obtenemos nuestra nueva versión de descenso por gradiente, incluyendo regularización:\n",
    "\n",
    "\n",
    "$$\\theta_0 := \\theta_0 - \\alpha \\frac{1}{m}\\sum_{i=1}^{m}  (h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_0 $$\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\left [ \\left ( \\frac{1}{m}\\sum_{i=1}^{m}  (h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j \\right \n",
    ") + \\frac{\\lambda}{m}\\theta_j  \\right ] \\text{   (simultáneamente para todos los $j \\in \\{1,2,\\ldots n\\}$)}$$\n",
    "\n",
    "En cada iteración, el valor de cada $\\theta_j$ (excepto $\\theta_0$ que, por convención, no se penaliza) se multiplica por $\\left ( 1 - \\frac{\\lambda}{m} \\right )$, que siempre es menor que 1, y por lo tanto hace que su valor se reduzca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluación\n",
    "\n",
    "Como en los problemas de regresión no estamos prediciendo valores discretos sino continuos, las medidas utilizadas para clasificación no nos van a servir (es prácticamente imposible acertar _exactamente_ un valor continuo). Por lo tanto, presentaremos dos de las medidas más utilizadas: el error absoluto medio (MAE, *mean absolut error*) y el error cuadrático medio (MSE, *mean squared error*).\n",
    "\n",
    "\n",
    "El error absoluto medio es la media (sobre todas las instancias de evaluación) de la diferencia (en valor absoluto) entre cada valor predicho y el valor real:\n",
    "\n",
    "$$ \\text{MAE} = \\frac{1}{m} \\sum_{i=1}^m | h_\\theta(x^{(i)}) - y^{(i)})|$$\n",
    "\n",
    "Por su parte, el error cuadrático medio corresponde a la media de los cuadrados de estas diferencias: \n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluación\n",
    "\n",
    "Ambos valores son similares, pero el MSE es más sensible a los outliers (valores que se separan mucho del comportamiento general), porque les da más peso. \n",
    "\n",
    "En el caso del MAE, sus valores tienen el mismo orden que $y$, por lo que podemos compararlo y analizar cuánto nuestros valores se apartan de los reales. Para hacer lo mismo con el mismo a partir del MSE, se suele utilizar el RMSE (*root mean squared error*), que es simplemente su raíz cuadrada:\n",
    "\n",
    "$$ \\text{RSME} = \\sqrt { \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2}$$\n",
    "\n",
    " Al igual que en el caso de la clasificación, estas medidas deberán evaluarse en un conjunto de instancias separada (y en lo posible con la misma distribución) que el conjunto de evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referencias\n",
    "- [Notas del curso CS229](http://cs229.stanford.edu/notes/cs229-notes1.pdf) de la Universidad de Stanford (disponible en la plataforma Coursera)\n",
    "- [Logistic Regression](https://web.stanford.edu/~jurafsky/slp3/5.pdf) - Capítulo 5 (draft) de la 3era edición del libro \"Speech and Language Processing\" de Martin and Jurafsky.\n",
    "- [Gradient Descent for Linear Regression Explained](https://blog.goodaudience.com/gradient-descent-for-linear-regression-explained-7c60bc414bdd) - Albert Lai."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
