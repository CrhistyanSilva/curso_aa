{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning\n",
    "\n",
    "### Aprendizaje Autom√°tico - Instituto de Computaci√≥n - UdelaR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a Mauricio Delbracio (@2ptmvd) por varias de las im√°genes e ideas para esta presentaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Tensorflow Playground](https://playground.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje de Representaciones\n",
    "\n",
    "Retomando la √∫ltima slide de la clase de redes neuronales...  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/mitchell_rep_learning.png\" alt=\"Rep.Learning\" style=\"width: 500px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje de Representaciones\n",
    "\n",
    "\n",
    "> ‚ÄúDeep learning allows computational models that are composed of\n",
    "> multiple processing layers to learn representations of data with\n",
    "> multiple levels of abstraction.‚Äù\n",
    "\n",
    "<div align=\"right\">Yann LeCun, Yoshua Bengio and Geoffrey Hinton, Deep Learning, Nature, 2015</div>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/science_2015.png\" alt=\"Science 2015\" style=\"width: 700px;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deep Learning\n",
    "\n",
    "- Redes con muchas capas no lineales en cascada\n",
    "- Cada capa usa la salida de la capa anterior como entrada, y obtiene representaciones con mayor nivel de abstracci√≥n \n",
    "- Busca generar una jerarqu√≠a de conceptos en las diferentes capas\n",
    "- Las representaciones de bajo nivel son comunes a las distintas categor√≠as\n",
    "- Las representaciones de alto nivel son m√°s globales, y m√°s invariantes\n",
    "- Im√°genes: Pixel $\\to$ bordes $\\to$ partes $\\to$ objetos\n",
    "- Entrenamiento punta a punta\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/ff_network_cat.PNG\" alt=\"Hidden cat\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aprendizaje de Representaciones\n",
    "\n",
    "- ML tradicional: clasificadores lineales sobre atributos hechos \"a mano\". \n",
    "\n",
    "- Problema m√°s dif√≠ciles: reconocimiento de im√°genes, sonido\n",
    "    - Robustos a variaciones\n",
    "    - Sensibles a variaciones m√≠nimas \n",
    "    \n",
    "- Soluci√≥n: stack de capas, varias de las cuales computan mapeos no lineales entre entradas y salidas\n",
    "    - Cada capa mejora la selectividad (distinguir gatos de animales parecidos) y la invarianza (identificar diferentes gatos, con diferencias de luz o de poses, por ejemplo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Un poco de historia... \n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/deep_learning_history_andrew_beam.jpg\" alt=\"Hidden cat\"  />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Redes Feedforward\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/red_feedforward.png\" alt=\"Feedforward networks\" style=\"width: 450px;\" />\n",
    "\n",
    "- Cada conjunto de neuronas computa la suma ponderada de sus entradas y lo pasa por una funci√≥n no lineal (e.g. ReLU)\n",
    "- No hay retroalimentaci√≥n\n",
    "- Aprendizaje basado en optimizaci√≥n (Backpropagation y descenso por gradiente estoc√°stico)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Teorema de Aproximaci√≥n Universal\n",
    "\n",
    "> Una red neuronal feedforward con una √∫nica capa oculta y un n√∫mero finito de neuronas puede aproximar cualquier funci√≥n continua en un espacio compacto de $\\mathbb{R}^n$\n",
    ">\n",
    ">                                                                (Cybenko, 1989; Hornik 1991)\n",
    "                    \n",
    "                   \n",
    "                    \n",
    "- Si encontramos los par√°metros, podemos representar gran variedad de funciones\n",
    "- El teorema no habla de _c√≥mo_ aprender los par√°metros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problemas de las redes FF\n",
    "\n",
    "- Much√≠simos par√°metros: sobreajuste üòà\n",
    "- Dif√≠ciles de entrenar: inicializaci√≥n, costo computacional\n",
    "\n",
    "- Soluci√≥n: forzar invarianzas en la arquitectura, reduciendo el n√∫mero de par√°metros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "- Algoritmo de deep learning que toma una imagen (o similar), asigna pesos a diferentes caracter√≠sticas, y permite diferenciarlas\n",
    "- Aprenden las caracter√≠sticas a partir de ejemplos\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/cnn_general.jpeg\" alt=\"Feedforward networks\" style=\"width: 600px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "- ¬øQu√© es una convoluci√≥n?\n",
    "\n",
    "- Operaci√≥n lineal entre una imagen y un filtro, que devuelve una nueva imagen\n",
    "\n",
    "<img src=\"https://docs.gimp.org/2.8/en/images/filters/examples/convolution-calculate.png\" alt=\"Convolution\" style=\"width: 600px;\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "- ¬øQu√© es una convoluci√≥n?\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/edge_detect.png\" alt=\"Convolution\"  style=\"width: 700px;\" />\n",
    "\n",
    "(M√°s ejemplos, en los manuales de [GIMP](https://docs.gimp.org/2.8/en/plug-in-convmatrix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "- ¬øQu√© es una convoluci√≥n?\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/convolution_image.png\" alt=\"Convolution\"  style=\"width: 700px;\" />\n",
    "\n",
    "- Las convoluciones pueden darnos una idea de partes \"importantes\" de la imagen(e.g. bordes)\n",
    "- N√≥tese que todos los cambios dependen solamente del filtro\n",
    "\n",
    "[Image kernels explained visually](https://setosa.io/ev/image-kernels/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/activation_map.png\" alt=\"Convolution\"  style=\"width: 500px;\" />\n",
    "\n",
    " <div align=\"right\">(Im√°genes del curso de \"Aprendizaje profundo para visi√≥n artificial\")</div>\n",
    "\n",
    "- Se impone (en lugar de aprenderla) la invarianza a traslaci√≥n $\\to$\n",
    "- Se comparten pesos, bajando el n√∫mero de par√°metros\n",
    "- Las caracter√≠sticas de bajo nivel son locales (el filtro refire a unos pocos p√≠xeles alrededor)\n",
    "- Submuestreamos al seguir avanzando en la red, para reducir a√∫n m√°s los par√°metros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/cnn_curso_iie1.png\" alt=\"Convolution\"  style=\"width: 700px;\" />\n",
    "\n",
    "- En cada capa, la nueva imagen s√≥lo depende de los pesos del filtro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/cnn_curso_iie2.png\" alt=\"Convolution\"  style=\"width: 700px;\" />\n",
    "\n",
    "- Cada filtro se va a especializar en algo distinto (dependiendo los pesos iniciales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/conv_activacion.png\" alt=\"Convolution\"  style=\"width: 600px;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/max_pooling.png\" alt=\"Convolution\"  style=\"width: 600px;\" />\n",
    "\n",
    "- La capa de pooling permite submuestrear la imagen, reduciendo el tama√±o, conservando caracter√≠sticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/pooling.png\" alt=\"Convolution\"  style=\"width: 600px;\" />\n",
    "\n",
    "- Hip√≥tesis: las caracter√≠sticas de m√°s alto nivel son m√°s gen√©ricas (y por lo tanto necesitamos menos par√°metros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### Lenet-5 - 1998\n",
    " \n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/lenet-5.png\" alt=\"Convolution\"   />\n",
    "\n",
    "- [LeCun, Y., Bottou, L., Bengio, Y. and Haffner, P. ‚ÄúGradient-based learning applied to document recognition.‚Äù Proc. IEEE (1998)](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)\n",
    "- Aplicada al reconocimiento de d√≠gitos escritos a mano\n",
    "- Faltaba hardware, especialmente GPUs, por lo que no funcionaba tan bien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AlexNet - 2012\n",
    " \n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/alexnet.png\" alt=\"Convolution\"   />\n",
    "\n",
    "- [Krizhevsky, Alex, Ilya Sutskever, Geoffrey E. Hinton.\n",
    "Imagenet classification with deep convolutional neural networks, NIPS 2012](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "- Entrenada a partir de [ImageNet](http://www.image-net.org/) (1 mill√≥n de im√°genes, 1.000 categor√≠as)\n",
    "- Tasa de error: 37.5% (top-1) y 17% (top-5), 10 puntos menos que el estado del arte al momento\n",
    "- En 2017, 29 de los 38 equipos de la competencia ten√≠an accuracy mayor a 95%\n",
    "- Hoy, ImageNet tiene 14 millones de im√°genes, con 20.000 categor√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representaciones distribuidas y Procesamiento de Lenguaje Natural\n",
    "\n",
    "- Una forma tradicional de representar palabras es a traves de una representaci√≥n dispersa, como un vector con n elementos (siendo n el tama√±o del vocabulario), donde s√≥lo hay valor en el componente i-√©simo, correspondiente a la palabra\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/one_hot_versus_dense_embeddings.png\" alt=\"Convolution\" style=\"width: 300px;\"  />\n",
    "\n",
    " <div align=\"right\">(Imagen tomadas de Fran√ßois Chollet with J. J. Allaire)</div>\n",
    "\n",
    "- En las representaciones distribuidas (*word embeddings*), cada palabra se representa por un vector denso (de largo 50-100, por ejemplo), y se obtienen asignando valores similares a palabras que aparecen en contextos similares\n",
    "- Estas representaciones son m√°s eficientes, porque capturan mejor la noci√≥n de sinonimia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neural Language Models\n",
    "\n",
    "- Entrenar una red neuronal para que, a partir una secuencia de palabras, prediga la siguiente (modelo de lenguaje).\n",
    "- Las palabras de la entrada se representan con vectores one-hot\n",
    "- Los pesos de la primera capa pueden verse como representaciones densas de la palabra\n",
    "- Capturan relaciones no expl√≠citas, solamente a partir del contexto\n",
    "- Tienen propiedades muy interesantes\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/pennington.png\" alt=\"Convolution\"  style=\"width: 600px;\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neural Language Models\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pln-fing-udelar/curso_aa/master/img/neural_language_model.png\" alt=\"Neural Language Model\"  style=\"width: 600px;\" />\n",
    "\n",
    "(Imagen tomada de Jurafsky & Martin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent Neural Networks\n",
    "\n",
    "- Las redes FF reciben como entrada (y devuelven como salida) vectores de largo fijo\n",
    "- Las RNN permiten trabajar con secuencias de vectores en la entrada, y en la salida \n",
    "\n",
    "<img src=\"http://karpathy.github.io/assets/rnn/diags.jpeg\" alt=\"RNN\"  style=\"width: 600px;\" />\n",
    "\n",
    "- 1 to 1: Clasificaci√≥n de im√°genes (FF)\n",
    "- 1 to M: Describir una imagen\n",
    "- M to 1: An√°lisis de Sentimiento\n",
    "- Many to Many: Traducci√≥n autom√°tica - Clasificaci√≥n de video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent Neural Networks\n",
    "\n",
    "- Las RNN procesan un elemento a la vez, y mantienen un vector de estado que contiene la historia de la secuencia\n",
    "- Pueden verse como redes FF, donde en cada paso discreto en el tiempo corresponde a una capa\n",
    "- La visi√≥n anterior permite utilizar backpropagation para aprender los pesos\n",
    "\n",
    "\n",
    "<img src=\"http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg\" alt=\"RNN\"  style=\"width: 600px;\" />\n",
    "\n",
    "- $x_t$ es la entrada en el paso $t$\n",
    "- $s_t$ es el estado en el paso $t$ (la \"memoria\" de la red)\n",
    "- la salida $y_t$ s√≥lo depende del estado y la entrada actual\n",
    "- En estas redes, las capas comparten los mismos pesos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent Neural Networks\n",
    "\n",
    "- Una RNN b√°sica tiene \n",
    "    - un vector $h$, llamado _estado_. \n",
    "    - una matriz $W_{hh}$ con los pesos utilizados al ajustar el vector de estado y obtener un estado nuevo\n",
    "    - una matriz $W_{xh}$ con los pesos utilizadols al ajustar el vector de estado con las entradas de cada paso\n",
    "    - una matriz $W_{hy}$ que relaciona al estado con las salidas\n",
    "    \n",
    "- En cada paso, se ajusta el estado utilizando la matriz de pesos y la entrada\n",
    "\n",
    "$$h_t = \\text{tanh}(W_{hh}h_{t-1} + W_{xh}x_{t})$$\n",
    "\n",
    "- ... y se devuelve la salida\n",
    "\n",
    "$$ y_t = W_{hy} h_{t-1}$$\n",
    "\n",
    "- Las RNN pueden verse como capas, y por lo tanto... hay Deep RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recurrent Neural Networks\n",
    "\n",
    "- Algunos problems:\n",
    "    - No son buenas recordando dependencias *long-term* \n",
    "    - Durante la backpropagation, surgen problemas de gradientes que desaparecen (vanishing gradients) o crecen demasiado (exploding gradients)\n",
    "\n",
    "- Algunas formas de evituarlos:\n",
    "    - Nuevas arquitecturas (GRU, LSTMS)\n",
    "    - Otras funciones de activaci√≥n (ReLUs)\n",
    "    - Formas alternativas de entrenarlas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSTMs\n",
    "\n",
    "- Las Long Short Term Memory (LSTM) son las redes recurrentes m√°s utilizadas hoy\n",
    "- La arquitectura es similar a las RNN, pero el c√°lculo del nuevo estado es un poco m√°s complejo\n",
    "- Est√°n dise√±adas para recordar dependencias lejanas en el tiempo\n",
    "- Utilizan mecanismos de \"gates\" para ver qu√© informaci√≥n se mantiene y cu√°l se agrega/elimina al estado en cada paso\n",
    "\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" alt=\"RNN\"  style=\"width: 500px;\" />\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" alt=\"RNN\"  style=\"width: 500px;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aplicaciones de las LSTMs\n",
    "\n",
    "- Modelos de lenguaje (orientados a palabras o caracteres)\n",
    "- Traducci√≥n autom√°tica\n",
    "- Anotaci√≥n de im√°genes \n",
    "- Generaci√≥n de texto escrito\n",
    "- Generaci√≥n de im√°ganes\n",
    "- Question Answering\n",
    "- Video to text \n",
    "\n",
    "[Quora: What are the various applications where LSTM networks have been successfully used?](https://www.quora.com/What-are-the-various-applications-where-LSTM-networks-have-been-successfully-used)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ¬øQu√© sigue? \n",
    "\n",
    "Preguntemos a los que saben [Deep Learning, Le Cun, Bengio, Hinton, 2015. Nature](https://s3.us-east-2.amazonaws.com/hkg-website-assets/static/pages/files/DeepLearning.pdf)... 24.000 citaciones: \n",
    "\n",
    "- Unsupervised learning\n",
    "- Progreso en visi√≥n artificial a trav√©s de ConvNets y RNNs que utilizan reinforcemente learning\n",
    "- Natural Language understanding\n",
    "- Combinar representation learning con razonamiento complejo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Open source Software\n",
    "\n",
    "- Gran parte del √©xito de las aplicaci√≥n de redes neuronales se debe a que todas las bibliotecas son de c√≥digo abierto\n",
    "\n",
    "- Principales caracter√≠sticas:\n",
    "    - Permiten acelerar c√°lculos matriciales utilizandos GPUs\n",
    "    - Permiten calcular autom√°ticamente los gradientes \n",
    "    - Permiten realizar especificaciones de alto nivel de las redes neuronales\n",
    "    \n",
    "\n",
    "- [Aqu√≠ algunas muy populares](https://www.upgrad.com/blog/top-deep-learning-frameworks/)\n",
    "\n",
    "- Ojo con JAX "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Referencias\n",
    "\n",
    "- [Deep Learning]((https://s3.us-east-2.amazonaws.com/hkg-website-assets/static/pages/files/DeepLearning.pdf)), LeCun, Bengio, Hinton. 2015. Science.\n",
    "- [Notas del curso \"Aprendizaje Profundo para Visi√≥n Artificial\"](https://iie.fing.edu.uy/~mdelbra/DL2018/slides/c6.pdf), Mauricio Delbracio, Jos√© Lezama, Guillermo Carbajal. Fing, UdelaR.\n",
    "- [Neural Networks and Neural Language Models](https://web.stanford.edu/~jurafsky/slp3/7.pdf) - Cap√≠tulo 7 (draft) de la 3era edici√≥n del libro \"Speech and Language Processing\" de Martin and Jurafsky.\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), A. Karpathy\n",
    "- [Recurrent Neural Networks Tutorial](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/), Denny Britz.\n",
    "- [Understanding LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/), Chris Olah.\n",
    "- [ConvNets: a modular perspective](https://colah.github.io/posts/2014-07-Conv-Nets-Modular/), Chris Olah\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
